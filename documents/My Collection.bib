@inproceedings{Lin2017,
abstract = {In this paper, we propose a consistent-aware deep learn-ing (CADL) approach for person re-identification in a cam-era network. Unlike most existing person re-identification methods which identify whether two pedestrian images are from the same person or not, our approach aims to obtain the maximal correct matches for the whole camera network. Different from recently proposed camera network based re-identification methods which only consider the consistent information in the matching stage to obtain a globally op-timal association, we exploit such consistent-aware infor-mation under a deep learning framework where both fea-ture representation and image matching are automatically learned. Specifically, we reach the globally optimal solu-tion and balance the performance between different cam-eras by optimizing the similarity and data association iter-atively with certain consistent constraints. Experimental re-sults show that our method obtains significant performance improvement and outperforms the state-of-the-art methods by large margins.},
author = {Lin, Ji and Ren, Liangliang and Lu, Jiwen and Feng, Jianjiang and Zhou, Jie},
booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2017.362},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin et al. - Unknown - Consistent-Aware Deep Learning for Person Re-identification in a Camera Network.pdf:pdf},
isbn = {978-1-5386-0457-1},
issn = {1063-6919},
pages = {3396--3405},
title = {{Consistent-Aware Deep Learning for Person Re-identification in a Camera Network}},
url = {http://openaccess.thecvf.com/content{\_}cvpr{\_}2017/papers/Lin{\_}Consistent-Aware{\_}Deep{\_}Learning{\_}CVPR{\_}2017{\_}paper.pdf http://ieeexplore.ieee.org/document/8099845/},
year = {2017}
}
@misc{Pumperla2017,
author = {Pumperla, Max},
title = {{Hyperas}},
url = {https://github.com/maxpumperla/hyperas},
year = {2017}
}
@misc{chollet2015keras,
author = {Chollet, Fran{\c{c}}ois},
publisher = {GitHub},
title = {{Keras}},
url = {https://github.com/fchollet/keras},
year = {2015}
}
@misc{Lutz2015,
author = {Lutz, Christian and Engesser, Thorsten},
publisher = {GitHub},
title = {{MOTLD}},
url = {https://github.com/evilsantabot/motld},
year = {2015}
}
@article{Huang,
abstract = {We define a new image feature called the color correlo-gram and use it for image indexing and comparison. This feature distills the spatial correlation of colors, and is both effective and inexpensive for content-based image retrieval. The correlogram robustly tolerates large changes in appear-ance and shape caused by changes in viewing positions, camera zooms, etc. Experimental evidence suggests that this new feature outperforms not only the traditional color histogram method but also the recently proposed histogram refinement methods for image indexing/retrieval.},
author = {Huang, Jing and Kumar, Ravi and Mitra, Mandar and Zhu, Wei-Jing and Zabih, Ramin},
title = {{Image Indexing Using Color Correlograms}}
}
@inproceedings{Qian2017,
abstract = {Person Re-identification (re-id) aims to match people across non-overlapping camera views in a public space. It is a challenging problem because many people captured in surveillance videos wear similar clothes. Consequently, the differences in their appearance are often subtle and only detectable at the right location and scales. Existing re-id models, particularly the recently proposed deep learning based ones match people at a single scale. In contrast, in this paper, a novel multi-scale deep learning model is proposed. Our model is able to learn deep discriminative feature representations at different scales and automatically determine the most suitable scales for matching. The importance of different spatial locations for extracting discriminative features is also learned explicitly. Experiments are carried out to demonstrate that the proposed model outperforms the state-of-the art on a number of benchmarks},
archivePrefix = {arXiv},
arxivId = {1709.05165},
author = {Qian, Xuelin and Fu, Yanwei and Jiang, Yu Gang and Xiang, Tao and Xue, Xiangyang},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2017.577},
eprint = {1709.05165},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qian et al. - Unknown - Multi-scale Deep Learning Architectures for Person Re-identification.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
pages = {5409--5418},
title = {{Multi-scale Deep Learning Architectures for Person Re-identification}},
url = {https://arxiv.org/pdf/1709.05165.pdf},
volume = {2017-Octob},
year = {2017}
}
@article{Almazan2018,
abstract = {Training a deep architecture using a ranking loss has become standard for the person re-identification task. Increasingly, these deep architectures include additional components that leverage part detections, attribute predictions, pose estimators and other auxiliary information, in order to more effectively localize and align discriminative image regions. In this paper we adopt a different approach and carefully design each component of a simple deep architecture and, critically, the strategy for training it effectively for person re-identification. We extensively evaluate each design choice, leading to a list of good practices for person re-identification. By following these practices, our approach outperforms the state of the art, including more complex methods with auxiliary components, by large margins on four benchmark datasets. We also provide a qualitative analysis of our trained representation which indicates that, while compact, it is able to capture information from localized and discriminative regions, in a manner akin to an implicit attention mechanism.},
archivePrefix = {arXiv},
arxivId = {1801.05339},
author = {Almazan, Jon and Gajic, Bojana and Murray, Naila and Larlus, Diane},
eprint = {1801.05339},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Almaz{\'{a}}n et al. - Unknown - Re-ID done right towards good practices for person re-identification.pdf:pdf},
journal = {CoRR},
title = {{Re-ID done right: towards good practices for person re-identification}},
url = {https://arxiv.org/pdf/1801.05339.pdf http://arxiv.org/abs/1801.05339},
volume = {1801.0},
year = {2018}
}
@inproceedings{Chung2017,
abstract = {Person re-identification is an important task in video surveillance systems. It can be formally defined as es-tablishing the correspondence between images of a person taken from different cameras at different times. In this pa-per, we present a two stream convolutional neural network where each stream is a Siamese network. This architec-ture can learn spatial and temporal information separately. We also propose a weighted two stream training objective function which combines the Siamese cost of the spatial and temporal streams with the objective of predicting a person's identity. We evaluate our proposed method on the publicly available PRID2011 and iLIDS-VID datasets and demon-strate the efficacy of our proposed method. On average, the top rank matching accuracy is 4{\%} higher than the accuracy achieved by the cross-view quadratic discriminant analy-sis used in combination with the hierarchical Gaussian de-scriptor (GOG+XQDA), and 5{\%} higher than the recurrent neural network method.},
author = {Chung, Dahjung and Tahboub, Khalid and Delp, Edward J},
booktitle = {2017 IEEE International Conference on Computer Vision (ICCV)},
doi = {10.1109/ICCV.2017.218},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chung, Tahboub, Delp - Unknown - A Two Stream Siamese Convolutional Neural Network For Person Re-Identification.pdf:pdf},
isbn = {978-1-5386-1032-9},
pages = {1992--2000},
title = {{A Two Stream Siamese Convolutional Neural Network for Person Re-identification}},
url = {http://openaccess.thecvf.com/content{\_}ICCV{\_}2017/papers/Chung{\_}A{\_}Two{\_}Stream{\_}ICCV{\_}2017{\_}paper.pdf http://ieeexplore.ieee.org/document/8237480/},
year = {2017}
}
@phdthesis{Robson2017,
author = {Robson, Thomas A. and Breckon, Toby P.},
file = {:home/tom/Documents/old/thirdYearWork/Project/reidThermal/General/Final Paper.pdf:pdf},
keywords = {Attributes,Computer Vision,Features,Person Re-Identification,Person Tracking,Re-ID,Thermal Imagery,Thermal Video},
mendeley-tags = {Attributes,Computer Vision,Features,Person Re-Identification,Person Tracking,Re-ID,Thermal Imagery,Thermal Video},
pages = {1--20},
school = {Durham University},
title = {{Camera-to-Camera Tracking for Person Re-identification within Thermal Imagery}},
type = {Bachelors Thesis},
year = {2017}
}
@inproceedings{Hadsell2006,
abstract = {Dimensionality reduction involves mapping a set of high dimensional input points onto a low dimensional manifold so that 'similar" points in input space are mapped to nearby points on the manifold. We present a method - called Dimensionality Reduction by Learning an Invariant Mapping (DrLIM) - for learning a globally coherent nonlinear function that maps the data evenly to the output manifold. The learning relies solely on neighborhood relationships and does not require any distancemeasure in the input space. The method can learn mappings that are invariant to certain transformations of the inputs, as is demonstrated with a number of experiments. Comparisons are made to other techniques, in particular LLE.},
author = {Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2006.100},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hadsell, Chopra, Lecun - Unknown - Dimensionality Reduction by Learning an Invariant Mapping(2).pdf:pdf},
isbn = {0769525970},
issn = {10636919},
pages = {1735--1742},
title = {{Dimensionality reduction by learning an invariant mapping}},
url = {http://www.cs.nyu.edu/},
volume = {2},
year = {2006}
}
@inproceedings{Matsukawa2017,
abstract = {This paper presents fine-tuned CNN features for person re-identification. Recently, features extracted from top layers of pre-trained Convolutional Neural Network (CNN) on a large annotated dataset, e.g., ImageNet, have been proven to be strong off-the-shelf descriptors for various recognition tasks. However, large disparity among the pre-trained task, i.e., ImageNet classification, and the target task, i.e., person image matching, limits performances of the CNN features for person re-identification. In this paper, we improve the CNN features by conducting a fine-tuning on a pedestrian attribute dataset. In addition to the classification loss for multiple pedestrian attribute labels, we propose new labels by combining different attribute labels and use them for an additional classification loss function. The combination attribute loss forces CNN to distinguish more person specific information, yielding more discriminative fea-tures. After extracting features from the learned CNN, we apply conventional metric learning on a target re-identification dataset for further increasing discriminative power. Experimental results on four challenging person re-identification datasets (VIPeR, CUHK, PRID450S and GRID) demonstrate the effectiveness of the proposed features.},
author = {Matsukawa, Tetsu and Suzuki, Einoshin},
booktitle = {Proceedings - International Conference on Pattern Recognition},
doi = {10.1109/ICPR.2016.7900000},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/icpr2016.pdf:pdf},
isbn = {9781509048472},
issn = {10514651},
pages = {2428--2433},
title = {{Person re-identification using CNN features learned from combination of attributes}},
year = {2017}
}
@inproceedings{Leal-Taixe2016,
abstract = {This paper introduces a novel approach to the task of data association within the context of pedestrian tracking, by introducing a two-stage learning scheme to match pairs of detections. First, a Siamese convolutional neural network (CNN) is trained to learn descriptors encoding local spatio-temporal structures between the two input image patches, aggregating pixel values and optical flow information. Second, a set of contextual features derived from the position and size of the compared input patches are combined with the CNN output by means of a gradient boosting classifier to generate the final matching probability. This learning approach is validated by using a linear programming based multi-person tracker showing that even a simple and efficient tracker may outperform much more complex models when fed with our learned matching probabilities. Results on publicly available sequences show that our method meets state-of-the-art standards in multiple people tracking.},
archivePrefix = {arXiv},
arxivId = {1604.07866},
author = {Leal-Taixe, Laura and Canton-Ferrer, Cristian and Schindler, Konrad},
booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
doi = {10.1109/CVPRW.2016.59},
eprint = {1604.07866},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leal-Taix{\'{e}}, Schindler - Unknown - Learning by tracking Siamese CNN for robust target association.pdf:pdf},
isbn = {9781467388504},
issn = {21607516},
pages = {418--425},
title = {{Learning by Tracking: Siamese CNN for Robust Target Association}},
url = {https://www.ethz.ch/content/dam/ethz/special-interest/baug/igp/photogrammetry-remote-sensing-dam/documents/pdf/learning-tracking-siamese.pdf},
year = {2016}
}
@inproceedings{Collomosse2017,
abstract = {We propose a novel measure of visual similarity for im-age retrieval that incorporates both structural and aes-thetic (style) constraints. Our algorithm accepts a query as sketched shape, and a set of one or more contextual im-ages specifying the desired visual aesthetic. A triplet net-work is used to learn a feature embedding capable of mea-suring style similarity independent of structure, delivering significant gains over previous networks for style discrim-ination. We incorporate this model within a hierarchical triplet network to unify and learn a joint space from two discriminatively trained streams for style and structure. We demonstrate that this space enables, for the first time, style-constrained sketch search over a diverse domain of digital artwork comprising graphics, paintings and drawings. We also briefly explore alternative query modalities.},
author = {Collomosse, John and Tech, Cornell},
booktitle = {ICCV},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Collomosse et al. - Unknown - Sketching with Style Visual Search with Sketches and Aesthetic Context.pdf:pdf},
pages = {31},
title = {{Sketching with Style : Visual Search with Sketches and Aesthetic Context}},
url = {http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Collomosse-ICCV-2017.pdf},
year = {2017}
}
@inproceedings{Shi2016,
abstract = {Person re-identification is challenging due to the large variations of pose, illumination, occlusion and camera view. Owing to these variations, the pedestrian data is distributed as highly-curved manifolds in the feature space, despite the current convolutional neural networks (CNN)'s capability of feature extraction. However, the distribution is unknown, so it is difficult to use the geodesic distance when comparing two samples. In practice, the current deep embedding methods use the Euclidean distance for the training and test. On the other hand, the manifold learning methods suggest to use the Euclidean distance in the local range, combining with the graphical relationship between samples, for approximating the geodesic distance. From this point of view, selecting suitable positive i.e. intra-class) training samples within a local range is critical for training the CNN embedding, especially when the data has large intra-class variations. In this paper, we propose a novel moderate positive sample mining method to train robust CNN for person re-identification, dealing with the problem of large variation. In addition, we improve the learning by a metric weight constraint, so that the learned metric has a better generalization ability. Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification, and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification. Therefore, the study presented in this paper may be useful in inspiring new designs of deep models for person re-identification.},
archivePrefix = {arXiv},
arxivId = {1611.00137},
author = {Shi, Hailin and Yang, Yang and Zhu, Xiangyu and Liao, Shengcai and Lei, Zhen and Zheng, Weishi and Li, Stan Z},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-46448-0_44},
eprint = {1611.00137},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shi et al. - Unknown - Embedding Deep Metric for Person Re-identification A Study Against Large Variations.pdf:pdf},
isbn = {9783319464473},
issn = {16113349},
keywords = {CNN,Deep learning,Person re-identification},
pages = {732--748},
pmid = {10463930},
title = {{Embedding deep metric for person Re-identification: A study against large variations}},
url = {https://arxiv.org/pdf/1611.00137.pdf},
volume = {9905 LNCS},
year = {2016}
}
@article{Zheng2016,
abstract = {We revisit two popular convolutional neural networks (CNN) in person re-identification (re-ID), i.e, verification and classification models. The two models have their respective advantages and limitations due to different loss functions. In this paper, we shed light on how to combine the two models to learn more discriminative pedestrian descriptors. Specifically, we propose a new siamese network that simultaneously computes identification loss and verification loss. Given a pair of training images, the network predicts the identities of the two images and whether they belong to the same identity. Our network learns a discriminative embedding and a similarity measurement at the same time, thus making full usage of the annotations. Albeit simple, the learned embedding improves the state-of-the-art performance on two public person re-ID benchmarks. Further, we show our architecture can also be applied in image retrieval.},
archivePrefix = {arXiv},
arxivId = {1611.05666},
author = {Zheng, Zhedong and Zheng, Liang and Yang, Yi},
eprint = {1611.05666},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zheng, Zheng, Yang - Unknown - A Discriminatively Learned CNN Embedding for Person Re-identification.pdf:pdf},
issn = {1611.05666},
journal = {ACM Transactions on Multimedia Computing, Communications, and Applications},
keywords = {Convolu-tional Neural Networks,Index Terms—Large-scale Person Re-identification},
number = {1},
title = {{A Discriminatively Learned CNN Embedding for Person Re-identification}},
url = {https://arxiv.org/pdf/1611.05666.pdf http://arxiv.org/abs/1611.05666},
volume = {14},
year = {2016}
}
@inproceedings{Cancela2014,
abstract = {Person re-identification methods have recently made tremendous progress on max-imizing re-identification accuracy between camera pairs. However, this line of work mostly shares an critical limitation -it assumes re-identification in a 'closed world'. That is, between a known set of people who all appear in both views of a single pair of cam-eras. This is clearly far from a realistic application scenario. In this study, we take a significant step toward a more realistic 'open world' scenario. We consider associating persons observed in more than two cameras where: multiple within-camera detections are possible; different people can transit between different cameras – so that there is only partial and unknown overlap of identity between people observed by each camera; and the total number of unique people among all cameras is itself unknown. To address this significantly more challenging open world scenario, we propose a novel framework based on online Conditional Random Field (CRF) inference. Experiments demonstrate the robustness of our approach in contrast to the limitations of conventional approaches in the open world context.},
author = {Cancela, Brais and Hospedales, Timothy M and Gong, Shaogang},
booktitle = {British Machine Vision Conference, BMVC 2014},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cancela, Hospedales, Gong - Unknown - Open-World Person Re-Identification by Multi-Label Assignment Inference.pdf:pdf},
title = {{Open-World Person Re-Identification by Multi-Label Assignment Inference}},
url = {https://www.eecs.qmul.ac.uk/{~}sgg/papers/CancelaEtAl{\_}BMVC14.pdf},
year = {2014}
}
@article{Kwak2017,
abstract = {—Pedestrian-vehicle accidents that occur at night are a major social problem worldwide. Advanced driver assistance systems that are equipped with cameras have been designed to automatically prevent such accidents. Among the various types of cameras used in such systems, far-infrared (FIR) cameras are favorable because they are invariant to illumination changes. Therefore, this paper focuses on a pedestrian nighttime tracking system with an FIR camera that is able to discern thermal energy and is mounted on the forward roof part of a vehicle. Since the temperature difference between the pedestrian and background depends on the season and the weather, we therefore propose two models to detect pedestrians according to the season and the weather, which are determined using Weber–Fechner's law. For tracking pedestrians, we perform real-time online learning to track pedestrians using boosted random ferns and update the trackers at each frame. In particular, we link detection responses to trajectories based on similarities in position, size, and appear-ance. There is no standard data set for evaluating the tracking performance using an FIR camera; thus, we created the Keimyung University tracking data set (KMUTD) by combining the KMU sudden pedestrian crossing (SPC) data set [21] for summer nights with additional tracking data for winter nights. The KMUTD con-tains video sequences involving a moving camera, moving pedestri-ans, sudden shape deformations, unexpected motion changes, and partial or full occlusions between pedestrians at night. The pro-posed algorithm is successfully applied to various pedestrian video sequences of the KMUTD; specifically, the proposed algorithm yields more accurate tracking performance than other existing methods. Index Terms—Pedestrian tracking, far-infrared (FIR) camera, Weber–Fechner's (W–F) law, boosted random ferns (BRFs), pedestrian tracking data set.},
author = {Kwak, Joon Young and Ko, Byoung Chul and Nam, Jae Yeal},
doi = {10.1109/TITS.2016.2569159},
isbn = {1524-9050},
issn = {15249050},
journal = {IEEE Transactions on Intelligent Transportation Systems},
keywords = {Pedestrian tracking,Weber-Fechner's (W-F) law,boosted random ferns (BRFs),far-infrared (FIR) camera,pedestrian tracking data set},
number = {1},
pages = {69--81},
pmid = {1626105},
title = {{Pedestrian Tracking Using Online Boosted Random Ferns Learning in Far-Infrared Imagery for Safe Driving at Night}},
volume = {18},
year = {2017}
}
@article{Liu2014,
abstract = {State-of-the-art person re-identification methods seek robust person matching through combining various feature types. Often, these features are implicitly assigned with generic weights, which are assumed to be universally and equally good for all individuals, independent of people's different appearances. In this study, we show that certain features play more important role than others under different viewing conditions. To explore this characteristic, we propose a novel unsupervised approach to bottom-up feature importance mining on-the-fly specific to each re-identification probe target image, so features extracted from different individuals are weighted adaptively driven by their salient and inherent appearance attributes. Extensive experiments on three public datasets give insights on how feature importance can vary depending on both the viewing condition and specific person's appearance, and demonstrate that unsupervised bottom-up feature importance mining specific to each probe image can facilitate more accurate re-identification especially when it is combined with generic universal weights obtained using existing distance metric learning methods. {\textcopyright} 2013 Elsevier Ltd.},
author = {Liu, Chunxiao and Gong, Shaogang and Loy, Chen Change},
doi = {10.1016/j.patcog.2013.11.001},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LiuGongLoy{\_}PR2013.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
number = {4},
title = {{On-the-fly feature importance mining for person re-identification}},
volume = {47},
year = {2014}
}
@article{Zhang2017,
abstract = {Person re-identification (re-id), an emerging problem in visual surveillance, deals with maintaining entities of individuals whilst they traverse various locations surveilled by a camera network. From a visual perspective re-id is challenging due to significant changes in visual appearance of individuals in cameras with different pose, illumination and calibration. Globally the challenge arises from the need to maintain structurally consistent matches among all the individual entities across different camera views. We propose PRISM, a structured matching method to jointly account for these challenges. We view the global problem as a weighted graph matching problem and estimate edge weights by learning to predict them based on the co-occurrences of visual patterns in the training examples. These co-occurrence based scores in turn account for appearance changes by inferring likely and unlikely visual co-occurrences appearing in training instances. We implement PRISM on single shot and multi-shot scenarios. PRISM uniformly outperforms state-of-the-art in terms of matching rate while being computationally efficient.},
archivePrefix = {arXiv},
arxivId = {1406.4444},
author = {Zhang, Ziming and Saligrama, Venkatesh},
doi = {10.1109/TCSVT.2016.2596159},
eprint = {1406.4444},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/07524750.pdf:pdf},
issn = {10518215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Co-occurrence of visual patterns,person reidentification (re-id),structured learning,weighted bipartite matching},
number = {3},
pages = {499--512},
title = {{PRISM: Person Reidentification via Structured Matching}},
volume = {27},
year = {2017}
}
@inproceedings{Loy2013,
abstract = {Existing person re-identification methods conventionally rely on labelled pairwise data to learn a task-specific distance metric for ranking. The value of unlabelled gallery instances is generally overlooked. In this study, we show that it is possible to propagate the query information along the unlabelled data manifold in an unsupervised way to obtain robust ranking results. In addition, we demonstrate that the performance of existing supervised metric learning methods can be significantly boosted once integrated into the proposed manifold ranking-based framework. Extensive evaluation is conducted on three benchmark datasets.},
author = {Loy, Chen Change and Liu, Chunxiao and Gong, Shaogang},
booktitle = {2013 IEEE International Conference on Image Processing, ICIP 2013 - Proceedings},
doi = {10.1109/ICIP.2013.6738736},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LoyEtAl{\_}ICIP2013.pdf:pdf},
isbn = {9781479923410},
keywords = {distance metric learning,manifold,person re-identification,ranking,video surveillance},
pages = {3567--3571},
title = {{Person re-identification by manifold ranking}},
year = {2013}
}
@article{Ma2017,
abstract = {Most existing person re-identification (ReID) methods rely only on the spatial appearance information from either one or multiple person images, whilst ignore the space-time cues readily available in video or image-sequence data. Moreover, they often assume the availability of exhaustively labelled cross-view pairwise data for every camera pair, making them non-scalable to ReID applications in real-world large scale camera networks. In this work, we introduce a novel video based person ReID method capable of accurately matching people across views from arbitrary unaligned image-sequences without any labelled pairwise data. Specifically, we introduce a new space-time person representation by encoding multiple granularities of spatio-temporal dynamics in form of time series. Moreover, a Time Shift Dynamic Time Warping (TS-DTW) model is derived for performing automatically alignment whilst achieving data selection and matching between inherently inaccurate and incomplete sequences in a unified way. We further extend the TS-DTW model for accommodating multiple feature-sequences of an image-sequence in order to fuse information from different descriptions. Crucially, this model does not require pairwise labelled training data (i.e. unsupervised) therefore readily scalable to large scale camera networks of arbitrary camera pairs without the need for exhaustive data annotation for every camera pair. We show the effectiveness and advantages of the proposed method by extensive comparisons with related state-of-the-art approaches using two benchmarking ReID datasets, PRID2011 and iLIDS-VID.},
archivePrefix = {arXiv},
arxivId = {1611.08512},
author = {Ma, Xiaolong and Zhu, Xiatian and Gong, Shaogang and Xie, Xudong and Hu, Jianming and Lam, Kin Man and Zhong, Yisheng},
doi = {10.1016/j.patcog.2016.11.018},
eprint = {1611.08512},
isbn = {9783319464480},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Action recognition,Gait recognition,Person re-identification,Spatio-temporal pyramids,Temporal sequence matching,Time shift,Video matching},
pages = {197--210},
title = {{Person re-identification by unsupervised video matching}},
volume = {65},
year = {2017}
}
@article{Wang2016,
abstract = {Current person re-identification (ReID) methods typically rely on single-frame imagery features, whilst ignoring space-time information from image sequences often available in the practical surveillance scenarios. Single-frame (single-shot) based visual appearance matching is inherently limited for person ReID in public spaces due to the challenging visual ambiguity and uncertainty arising from non-overlapping camera views where viewing condition changes can cause significant people appearance variations. In this work, we present a novel model to automatically select the most discriminative video fragments from noisy/incomplete image sequences of people from which reliable space-time and appearance features can be computed, whilst simultaneously learning a video ranking function for person ReID. Using the PRID{\$}2011{\$}, iLIDS-VID, and HDA+ image sequence datasets, we extensively conducted comparative evaluations to demonstrate the advantages of the proposed model over contemporary gait recognition, holistic image sequence matching and state-of-the-art single-/multi-shot ReID methods.},
archivePrefix = {arXiv},
arxivId = {1601.06260},
author = {Wang, Taiqing and Gong, Shaogang and Zhu, Xiatian and Wang, Shengjin},
doi = {10.1109/TPAMI.2016.2522418},
eprint = {1601.06260},
isbn = {978-3-319-10592-5},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Person re-identification,Video ranking,discriminative selection,multi-instance ranking,sequence matching},
number = {12},
pages = {2501--2514},
pmid = {7393860},
title = {{Person Re-Identification by Discriminative Selection in Video Ranking}},
volume = {38},
year = {2016}
}
@article{Zheng2016a,
abstract = {—Solving the problem of matching people across non-overlapping multi-camera views, known as person re-identification (re-id), has received increasing interests in computer vision. In a real-world application scenario, a watch-list (gallery set) of a handful of known target people are provided with very few (in many cases only a single) image(s) (shots) per target. Existing re-id methods are largely unsuitable to address this open-world re-id challenge because they are designed for (1) a closed-world scenario where the gallery and probe sets are assumed to contain exactly the same people, (2) person-wise identification whereby the model attempts to verify exhaustively against each individual in the gallery set, and (3) learning a matching model using multi-shots. In this paper, a novel transfer local relative distance comparison (t-LRDC) model is formulated to address the open-world person re-identification problem by one-shot group-based verification. The model is designed to mine and transfer useful information from a labelled open-world non-target dataset. Extensive experiments demonstrate that the proposed approach outperforms both non-transfer learning and existing transfer learning based re-id methods.},
author = {Zheng, Wei Shi and Gong, Shaogang and Xiang, Tao},
doi = {10.1109/TPAMI.2015.2453984},
isbn = {2014040265},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Group-based verification,open-world reidentification,transfer relative distance comparison},
number = {3},
pages = {591--606},
title = {{Towards Open-World Person Re-Identification by One-Shot Group-Based Verification}},
volume = {38},
year = {2016}
}
@inproceedings{Wang2016a,
abstract = {Person re-identification has been usually solved as ei-ther the matching of single-image representation (SIR) or the classification of cross-image representation (CIR). In this work, we exploit the connection between these two cat-egories of methods, and propose a joint learning frame-work to unify SIR and CIR using convolutional neural net-work (CNN). Specifically, our deep architecture contain-s one shared sub-network together with two sub-networks that extract the SIRs of given images and the CIRs of given image pairs, respectively. The SIR sub-network is required to be computed once for each image (in both the probe and gallery sets), and the depth of the CIR sub-network is required to be minimal to reduce computational burden. Therefore, the two types of representation can be jointly op-timized for pursuing better matching accuracy with moder-ate computational cost. Furthermore, the representations learned with pairwise comparison and triplet comparison objectives can be combined to improve matching perfor-mance. Experiments on the CUHK03, CUHK01 and VIPeR datasets show that the proposed method can achieve favor-able accuracy while compared with state-of-the-arts.},
author = {Wang, Faqiang and Zuo, Wangmeng and Lin, Liang and Zhang, David and Zhang, Lei},
booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2016.144},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/07780513.pdf:pdf},
isbn = {978-1-4673-8851-1},
issn = {10636919},
pages = {1288--1296},
title = {{Joint Learning of Single-Image and Cross-Image Representations for Person Re-identification}},
url = {http://ieeexplore.ieee.org/document/7780513/},
year = {2016}
}
@inproceedings{Ko2016,
abstract = {According to a report of [1], night time and poor illumination driving is overall 2-3 times more dangerous then day time. For example, young people aged 18-24 were killed between 21:00 and 05:59 (the night-time and early morning) on week-days in the EU-23 countries because of road accident in 2010. As the similar pattern with EU, most pedestrian-vehicle accidents occur between 6 p.m. and 8 a.m., and the rate of pedestrian fatalities is highest between 4 a.m. and 6 a.m. in South Korea according to [2]. Among several factors such as inebriated drivers and pedestrian, drowsiness, decreased visibility is the major cause of pedestrian-vehicle accident at night. To reduce the accident owing to driver's inattention at night, recent advanced driver assistance system (ADAS) has been researching on automatic pedestrian detection and tracking using night vision camera. Therefore, this tutorial focuses on introducing a multiple pedestrians tracking system using a thermal camera that is able to discern thermal energy at night-time. {\textcopyright} 2016 IEEE.},
author = {Ko, Byoung Chul and Kwak, Joon Young and Nam, Jae Yeal},
booktitle = {IEEE Intelligent Vehicles Symposium, Proceedings},
doi = {10.1109/IVS.2016.7535367},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/07535367.pdf:pdf},
isbn = {9781509018215},
issn = {1524-9050},
pages = {78--79},
title = {{Online learning based multiple pedestrians tracking in thermal imagery for safe driving at night}},
volume = {2016-Augus},
year = {2016}
}
@article{Hare2015,
abstract = {Adaptive tracking-by-detection methods are widely used in computer vision for tracking arbitrary objects. Current approaches treat the tracking problem as a classification task and use online learning techniques to update the ob-ject model. However, for these updates to happen one needs to convert the estimated object position into a set of la-belled training examples, and it is not clear how best to perform this intermediate step. Furthermore, the objective for the classifier (label prediction) is not explicitly coupled to the objective for the tracker (accurate estimation of ob-ject position). In this paper, we present a framework for adaptive visual object tracking based on structured output prediction. By explicitly allowing the output space to ex-press the needs of the tracker, we are able to avoid the need for an intermediate classification step. Our method uses a kernelized structured output support vector machine (SVM), which is learned online to provide adaptive track-ing. To allow for real-time application, we introduce a bud-geting mechanism which prevents the unbounded growth in the number of support vectors which would otherwise oc-cur during tracking. Experimentally, we show that our al-gorithm is able to outperform state-of-the-art trackers on various benchmark videos. Additionally, we show that we can easily incorporate additional features and kernels into our framework, which results in increased performance.},
author = {Hare, Sam and Saffari, Amir and Torr, Philip H S and Computer, Sony and Europe, Entertainment},
doi = {10.1109/TPAMI.2015.2509974},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hare, Saffari, Torr - Unknown - Struck Structured Output Tracking with Kernels.pdf:pdf},
isbn = {9781457711022},
issn = {0162-8828},
number = {c},
pages = {1--14},
pmid = {26700968},
title = {{Struck: Structured Output Tracking with Kernels}},
url = {https://57df853f-a-b7668c4d-s-sites.googlegroups.com/a/samhare.net/samhare/research/files/iccv2011{\_}struck.pdf?attachauth=ANoY7cqxFWUYQ-1RdWWna4HGoqiy6NrZDJ4fO2isivHObXFd5-mB4QnignIHd-hYo27fcv8iBrnZtdXb91Gu8wyjzL2lCwVraKkb4AcQMwvs7gTomyM8pl{\_}ev1X2zX9mVYHPwl},
volume = {8828},
year = {2015}
}
@article{Felsberg2016,
abstract = {{\textcopyright} 2015 IEEE.The Thermal Infrared Visual Object Tracking challenge 2015, VOT-TIR2015, aims at comparing short-term single-object visual trackers that work on thermal infrared (TIR) sequences and do not apply pre-learned models of object appearance. VOT-TIR2015 is the first benchmark on short-term tracking in TIR sequences. Results of 24 trackers are presented. For each participating tracker, a short description is provided in the appendix. The VOT-TIR2015 challenge is based on the VOT2013 challenge, but introduces the following novelties: (i) the newly collected LTIR (Link - ping TIR) dataset is used, (ii) the VOT2013 attributes are adapted to TIR data, (iii) the evaluation is performed using insights gained during VOT2013 and VOT2014 and is similar to VOT2015.},
author = {Felsberg, Michael and Berg, Amanda and H{\"{a}}ger, Gustav and Ahlberg, J{\"{o}}rgen and Kristan, Matej and Matas, Jiri and Leonardis, Ale{\v{s}} and {\v{C}}ehovin, Luka and Fern{\'{a}}ndez, Gustavo and Voj{\'{i}}r˜, Tom{\'{a}}{\v{s}} and Nebehay, Georg and Pflugfelder, Roman and Luke{\v{z}}i{\v{c}}, Alan and Garcia-Martin, Alvaro and Saffari, Amir and Li, Ang and Montero, Andr{\'{e}}s Sol{\'{i}}s and Zhao, Baojun and Schmid, Cordelia and Chen, Dapeng and Du, Dawei and Khan, Fahad Shahbaz and Porikli, Fatih and Zhu, Gao and Zhu, Guibo and Lu, Hanqing and Kieritz, Hilke and Li, Hongdong and Qi, Honggang and Jeong, Jae Chan and Cho, Jae Il and Lee, Jae Yeong and Zhu, Jianke and Li, Jiatong and Feng, Jiayi and Wang, Jinqiao and Kim, Ji Wan and Lang, Jochen and Martinez, Jose M. and Xue, Kai and Alahari, Karteek and Ma, Liang and Ke, Lipeng and Wen, Longyin and Bertinetto, Luca and Danelljan, Martin and Arens, Michael and Tang, Ming and Chang, Ming Ching and Miksik, Ondrej and Torr, Philip H.S. and Martin-Nieto, Rafael and Lagani{\`{e}}re, Robert and Hare, Sam and Lyu, Siwei and Zhu, Song Chun and Becker, Stefan and Hicks, Stephen L. and Golodetz, Stuart and Choi, Sunglok and Wu, Tianfu and H{\"{u}}bner, Wolfgang and Zhao, Xu and Hua, Yang and Li, Yang and Lu, Yang and Li, Yuezun and Yuan, Zejian and Hong, Zhibin},
doi = {10.1109/ICCVW.2015.86},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/07406435.pdf:pdf},
isbn = {9781467383905},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
keywords = {Australia,Benchmark testing,Cameras,Object tracking,Target tracking,Visualization},
pages = {639--651},
title = {{The Thermal Infrared Visual Object Tracking VOT-TIR2015 Challenge Results}},
volume = {2016-Febru},
year = {2016}
}
@article{Zhang2014,
abstract = {One key issue for people re-identification is to find good features or representation to bridge the gaps among different appearances of the same people, which is introduced by large variances in view point, illumination and non-rigid deformation. In this paper, we create a deep convolutional neural network (deep CNN) to solve this problem and integrate feature learning and re-identification into one framework. In order to deal with such ranking-like comparison problem, we introduce a linear support vector machine (linear SVM) to replace conventional softmax activation function. Instead of learning cross-entropy loss, we adopt a margin-based loss of pair-wise image to measure the similarity of the comparing pair. Although the proposed model is quite simple, the experimental result shows encouraging performance of our method.},
author = {Zhang, Guanwen and Kato, Jien and Wang, Yu and Mase, Kenji},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/07295083.pdf:pdf},
isbn = {9789897580093},
journal = {VISAPP 2014 - Proceedings of the 9th International Conference on Computer Vision Theory and Applications},
keywords = {Deep convolutional neural network,Linear SVM,People re-identification},
pages = {216--223},
title = {{People re-identification using deep convolutional neural network}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84906896155{\&}partnerID=tZOtx3y1},
volume = {3},
year = {2014}
}
@inproceedings{Felsberg2016a,
abstract = {{\textcopyright} Springer International Publishing Switzerland 2016.The Thermal Infrared Visual Object Tracking challenge 2016, VOT-TIR2016, aims at comparing short-term single-object visual trackers that work on thermal infrared (TIR) sequences and do not apply pre-learned models of object appearance. VOT-TIR2016 is the second benchmark on short-term tracking in TIR sequences. Results of 24 trackers are presented. For each participating tracker, a short description is provided in the appendix. The VOT-TIR2016 challenge is similar to the 2015 challenge, the main difference is the introduction of new, more difficult sequences into the dataset. Furthermore, VOT-TIR2016 evaluation adopted the improvements regarding overlap calculation in VOT2016. Compared to VOT-TIR2015, a significant general improvement of results has been observed, which partly compensate for the more difficult sequences. The dataset, the evaluation kit, as well as the results are publicly available at the challenge website.},
author = {Felsberg, Michael and Kristan, Matej and Matas, Jiři and Leonardis, Ale{\v{s}} and Pflugfelder, Roman and H{\"{a}}ger, Gustav and Berg, Amanda and Eldesokey, Abdelrahman and Ahlberg, J{\"{o}}rgen and {\v{C}}ehovin, Luka and Voj{\'{i}}r, Tom{\'{a}}{\v{s}} and Luke{\v{z}}i{\v{c}}, Alan and Fern{\'{a}}ndez, Gustavo and Petrosino, Alfredo and Martin, Alvaro Garcia and Montero, Andr{\'{e}}s Sol{\'{i}}s and Varfolomieiev, Anton and Erdem, Aykut and Han, Bohyung and Chang, Chang Ming and Du, Dawei and Erdem, Erkut and Khan, Fahad Shahbaz and Porikli, Fatih and Zhao, Fei and Bunyak, Filiz and Battistone, Francesco and Zhu, Gao and Seetharaman, Guna and Li, Hongdong and Qi, Honggang and Bischof, Horst and Possegger, Horst and Nam, Hyeonseob and Valmadre, Jack and Zhu, Jianke and Feng, Jiayi and Lang, Jochen and Martinez, Jose M and Palaniappan, Kannappan and Lebeda, Karel and Gao, Ke and Mikolajczyk, Krystian and Wen, Longyin and Bertinetto, Luca and Poostchi, Mahdieh and Maresca, Mario and Danelljan, Martin and Arens, Michael and Tang, Ming and Baek, Mooyeol and Fan, Nana and Shakarji, Noor Al and Miksik, Ondrej and Akin, Osman and Torr, Philip H.S. and Huang, Qingming and Martin-Nieto, Rafael and Pelapur, Rengarajan and Bowden, Richard and Lagani{\`{e}}re, Robert and Krah, Sebastian B and Li, Shengkun and Yao, Shizeng and Hadfield, Simon and Lyu, Siwei and Becker, Stefan and Golodetz, Stuart and Hu, Tao and Mauthner, Thomas and Santopietro, Vincenzo and Li, Wenbo and H{\"{u}}bner, Wolfgang and Li, Xin and Li, Yang and Xu, Zhan and He, Zhenyu},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-48881-3_55},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Felsberg et al. - Unknown - The Thermal Infrared Visual Object Tracking VOT-TIR2016 Challenge Results.pdf:pdf},
isbn = {9783319488806},
issn = {16113349},
keywords = {Object tracking,Performance evaluation,Thermal IR,VOT},
pages = {824--849},
title = {{The thermal infrared visual object tracking VOT-TIR2016 challenge results}},
url = {http://akme-a2.iosb.fraunhofer.de/EatThisGoogleScholar/2016{\_}The thermal infrared visual object tracking VOT-TIR2016 challenge results.pdf},
volume = {9914 LNCS},
year = {2016}
}
@article{Ahmed2015,
abstract = {In this work, we propose a method for simultaneously learning features and a corresponding similarity metric for person re-identification. We present a deep convolutional architecture with layers specially designed to address the problem of re-identification. Given a pair of images as input, our network outputs a similarity value indicating whether the two input images depict the same person. Novel elements of our architecture include a layer that computes cross-input neighborhood differences, which capture local relationships between the two input images based on mid- level features from each input image. A high-level summary of the outputs of this layer is computed by a layer of patch summary features, which are then spatially integrated in subsequent layers. Our method significantly outperforms the state of the art on both a large data set (CUHK03) and a medium-sized data set (CUHK01), and is resistant to over- fitting. We also demonstrate that by initially training on an unrelated large data set before fine-tuning on a small target data set, our network can achieve results comparable to the state of the art even on a small data set (VIPeR). 1.},
archivePrefix = {arXiv},
arxivId = {1406.4216},
author = {Ahmed, Ejaz and Jones, Michael and Marks, Tim K},
doi = {10.1109/CVPR.2015.7299016},
eprint = {1406.4216},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, Jones, Marks - Unknown - An Improved Deep Learning Architecture for Person Re-Identification.pdf:pdf},
isbn = {9781467369640},
issn = {10636919},
journal = {Computer Vision and Pattern Recognition (CVPR)},
pages = {3908--3916},
pmid = {22732661},
title = {{An Improved Deep Learning Architecture for Person Re-Identification}},
url = {https://www.cv-foundation.org/openaccess/content{\_}cvpr{\_}2015/papers/Ahmed{\_}An{\_}Improved{\_}Deep{\_}2015{\_}CVPR{\_}paper.pdf},
year = {2015}
}
@article{Kalal2010,
abstract = {—This paper investigates long-term tracking of unknown objects in a video stream. The object is defined by its location and extent in a single frame. In every frame that follows, the task is to determine the object's location and extent or indicate that the object is not present. We propose a novel tracking framework (TLD) that explicitly decomposes the long-term tracking task into tracking, learning and detection. The tracker follows the object from frame to frame. The detector localizes all appearances that have been observed so far and corrects the tracker if necessary. The learning estimates detector's errors and updates it to avoid these errors in the future. We study how to identify detector's errors and learn from them. We develop a novel learning method (P-N learning) which estimates the errors by a pair of " experts " : (i) P-expert estimates missed detections, and (ii) N-expert estimates false alarms. The learning process is modeled as a discrete dynamical system and the conditions under which the learning guarantees improvement are found. We describe our real-time implementation of the TLD framework and the P-N learning. We carry out an extensive quantitative evaluation which shows a significant improvement over state-of-the-art approaches.},
author = {Kalal, Zdenek and Mikolajczyk, Krystian and Matas, Jiri},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalal, Mikolajczyk, Matas - 2010 - Tracking-Learning-Detection.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Index Terms—Long-term tracking,bootstrapping,learning from video,real-time,semi-supervised learning},
number = {1},
title = {{Tracking-Learning-Detection}},
url = {http://kahlan.eps.surrey.ac.uk/featurespace/tld/Publications/2011{\_}tpami},
volume = {6},
year = {2010}
}
@article{T.P.BreckonA.GaszczakJ.HanM.L.Eichner2013,
author = {{T.P. Breckon, A. Gaszczak, J. Han, M.L. Eichner}, S.E. Barnes},
journal = {In Proc. SPIE Emerging Technologies in Security and Defence: Unmanned Sensor Systems, SPIE},
number = {1},
pages = {1--19},
title = {{Multi-Modal Target Detection for Autonomous Wide Area Search and Surveillance}},
volume = {8899},
year = {2013}
}
@book{solomonbreckon10fundamentals,
author = {Solomon, C J and Breckon, T P},
doi = {10.1002/9780470689776},
isbn = {0470844736},
publisher = {Wiley-Blackwell},
title = {{Fundamentals of Digital Image Processing: A Practical Approach with Examples in Matlab}},
url = {http://www.fundipbook.com},
year = {2010}
}
@article{Fukunaga1990,
abstract = {This completely revised second edition presents an introduction to statistical pattern recognition. Pattern recognition in general covers a wide range of problems: it is applied to engineering problems, such as character readers and wave form analysis as well as to brain modeling in biology and psychology. Statistical decision and estimation, which are the main subjects of this book, are regarded as fundamental to the study of pattern recognition. This book is appropriate as a text for introductory courses in pattern recognition and as a reference book for workers in the field. Each chapter contains computer projects as well as exercises.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Fukunaga, Keinosuke},
doi = {10.1016/0098-3004(96)00017-9},
eprint = {arXiv:1011.1669v3},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fukunaga - 1990 - Statistical Pattern Recognition.pdf:pdf},
isbn = {9780080478654},
issn = {00983004},
journal = {Pattern Recognition},
keywords = {Referex},
number = {7},
pages = {833--834},
pmid = {21124870},
title = {{Statistical Pattern Recognition}},
url = {ftp://91.193.236.10/pub/docs/linux-support/computer science/Machine learning/Pattern recognition/Introduction to Statistical Pattern Recognition 2nd Ed -  Keinosuke Fukunaga.pdf http://linkinghub.elsevier.com/retrieve/pii/0098300496000179},
volume = {22},
year = {1990}
}
@article{Mahalanobis1936,
author = {Mahalanobis, PC},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahalanobis - Unknown - On the Generalized Distance in Statistics.pdf:pdf},
journal = {In Proceedings National Institute of Science, India},
number = {1},
pages = {49--55},
title = {{on the Generalized Distance in Statistics}},
url = {http://insa.nic.in/writereaddata/UpLoadedFiles/PINSA/Vol02{\_}1936{\_}1{\_}Art05.pdf},
volume = {2},
year = {1936}
}
@article{Mahalanobis,
author = {Mahalanobis, P.C.},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahalanobis - Unknown - On the Generalized Distance in Statistics.pdf:pdf},
title = {{On the Generalized Distance in Statistics}},
url = {http://insa.nic.in/writereaddata/UpLoadedFiles/PINSA/Vol02{\_}1936{\_}1{\_}Art05.pdf}
}
@article{Farneback2003,
abstract = {This paper presents a novel two-frame motion estimation algorithm. The first step is to approximate each neighborhood of both frames by quadratic polynomials, which can be done efficiently using the polynomial expansion transform. From observing how an exact polynomial transforms under translation a method to estimate displacement fields from the polynomial expansion coefficients is derived and after a series of refinements leads to a robust algorithm. Evaluation on the Yosemite sequence shows good results.},
author = {Farneback, Gunnar},
doi = {10.1007/3-540-45103-X_50},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farneback - 2003 - Two-Frame Motion Estimation Based on Polynomial Expansion.pdf:pdf},
isbn = {978-3-540-40601-3},
issn = {03029743},
journal = {Lecture Notes in Computer Science},
number = {1},
pages = {363--370},
title = {{Two-Frame Motion Estimation Based on Polynomial Expansion}},
url = {http://www.isy.liu.se/cvl/},
volume = {2749},
year = {2003}
}
@article{Roth2014,
abstract = {Recently, Mahalanobis metric learning has gained a considerable inter-est for single-shot person re-identification. The main idea is to build on an existing image representation and to learn a metric that reflects the visual camera-to-camera transitions, allowing for a more powerful classification. The goal of this chapter is twofold. We first review the main ideas of Mahalanobis metric learning in general and then give a detailed study on different approaches for the task of single-shot person re-identification, also comparing to the state-of-the-art. In particular, for our experiments we used Linear Discriminant Metric Learning (LDML), Information Theoretic Metric Learning (ITML), Large Margin Nearest Neighbor (LMNN), Large Margin Nearest Neighbor with Rejection (LMNN-R), Efficient Impostor-based Met-ric Learning (EIML), and KISSME. For our evaluations we used four different pub-licly available datasets (i.e., VIPeR, ETHZ, PRID 2011, and CAVIAR4REID). Ad-ditionally, we generated the new, more realistic PRID 450S dataset, where we also provide detailed segmentations. For the latter one, we also evaluated the influence of using well segmented foreground and background regions. Finally, the correspond-ing results are presented and discussed.},
author = {Roth, Peter M and Hirzer, Martin and K{\"{o}}stinger, Martin and Beleznai, Csaba and Bischof, Horst},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roth et al. - 2014 - Mahalanobis Distance Learning for Person Re-Identification.pdf:pdf},
title = {{Mahalanobis Distance Learning for Person Re-Identification}},
url = {https://pdfs.semanticscholar.org/f62d/71e701c9fd021610e2076b5e0f5b2c7c86ca.pdf},
year = {2014}
}
@article{Nguyen2016,
abstract = {With higher demand from users, surveillance systems are currently being designed to provide more information about the observed scene, such as the appearance of objects, types of objects, and other information extracted from detected objects. Although the recognition of gender of an observed human can be easily performed using human perception, it remains a difficult task when using computer vision system images. In this paper, we propose a new human gender recognition method that can be applied to surveillance systems based on quality assessment of human areas in visible light and thermal camera images. Our research is novel in the following two ways: First, we utilize the combination of visible light and thermal images of the human body for a recognition task based on quality assessment. We propose a quality measurement method to assess the quality of image regions so as to remove the effects of background regions in the recognition system. Second, by combining the features extracted using the histogram of oriented gradient (HOG) method and the measured qualities of image regions, we form a new image features, called the weighted HOG (wHOG), which is used for efficient gender recognition. Experimental results show that our method produces more accurate estimation results than the state-of-the-art recognition method that uses human body images.},
author = {Nguyen, Dat and Park, Kang},
doi = {10.3390/s16071134},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Park - 2016 - Enhanced Gender Recognition System Using an Improved Histogram of Oriented Gradient (HOG) Feature from Quality Ass.pdf:pdf},
issn = {1424-8220},
journal = {Sensors},
keywords = {gender recognition,image quality assessment,thermal camera image,visible light camera image},
month = {jul},
number = {7},
pages = {1134},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Enhanced Gender Recognition System Using an Improved Histogram of Oriented Gradient (HOG) Feature from Quality Assessment of Visible Light and Thermal Images of the Human Body}},
url = {http://www.mdpi.com/1424-8220/16/7/1134},
volume = {16},
year = {2016}
}
@article{Hu1962,
abstract = {In this paper a theory of two-dimensional moment invariants for planar geometric figures is presented. A fundamental theorem is established to relate such moment invariants to the well-known algebraic invariants. Complete systems of moment invariants under translation, similitude and orthogonal transformations are derived. Some moment invariants under general two-dimensional linear transformations are also included. Both theoretical formulation and practical models of visual pattern recognition based upon these moment invariants are discussed. A simple simulation program together with its performance are also presented. It is shown that recognition of geometrical patterns and alphabetical characters independently of position, size and orientation can be accomplished. It is also indicated that generalization is possible to include invariance with parallel projection.},
author = {Hu, Ming-Kuei},
doi = {10.1109/TIT.1962.1057692},
isbn = {0096-1000},
issn = {0018-9448},
journal = {Information Theory, IEEE Transactions on},
keywords = {geometric,invariants,moments,pattern,recognition},
pages = {179--187},
title = {{Visual pattern recognition by moment invariants}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1057692},
volume = {8},
year = {1962}
}
@article{HornSchunck1981,
author = {Horn, Berthold K.P. and Schunck, Brian G.},
doi = {10.1016/0004-3702(81)90024-2},
issn = {00043702},
journal = {Artificial Intelligence},
month = {aug},
number = {1-3},
pages = {185--203},
title = {{Determining optical flow}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0004370281900242},
volume = {17},
year = {1981}
}
@book{Dawson-Howe2014,
author = {Dawson-Howe, Kenneth},
edition = {1st},
isbn = {1118848454, 9781118848456},
publisher = {Wiley Publishing},
title = {{A Practical Introduction to Computer Vision with OpenCV}},
year = {2014}
}
@book{FlusserSukZitova2009,
author = {Flusser, Jan and Zitova, Barbara and Suk, Tomas},
isbn = {0470699876, 9780470699874},
publisher = {Wiley Publishing},
title = {{Moments and Moment Invariants in Pattern Recognition}},
year = {2009}
}
@article{Bishop,
author = {Bishop, Gary and Welch, Greg},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bishop, Welch - 2001 - An Introduction to the Kalman Filter.pdf:pdf},
journal = {SIGGRAPH},
title = {{An Introduction to the Kalman Filter}},
url = {http://www.cs.unc.edu/{~}{\%}7Bwelch,},
volume = {Course 8},
year = {2001}
}
@article{RainerLienhartandJochenMaydt2002,
abstract = {Recently Viola et al. [5] have introduced a rapid object detection scheme based on a boosted cascade of simple features. In this paper we introduce a novel set of rotated haar-like features, which significantly enrich this basic set of simple haar-like features and which can also be calculated very efficiently. At a given hit rate our sample face detector shows off on average a 10{\%} lower false alarm rate by means of using these additional rotated features. We also present a novel post optimization procedure for a given boosted cascade improving on average the false alarm rate further by 12.5{\%}. Using both enhancements the number of false detections is only 24 at a hit rate of 82.3{\%} on the CMU face set [7].},
author = {{Rainer Lienhart and Jochen Maydt}},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rainer Lienhart and Jochen Maydt - 2002 - An Extended Set of Haar-like Features for Rapid Object Detection.pdf:pdf},
journal = {International Conference on Image Processing. Proceedings. 2002},
title = {{An Extended Set of Haar-like Features for Rapid Object Detection}},
year = {2002}
}
@inproceedings{Viola,
abstract = {This paper describes a machine learning approach for vi-sual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the " Integral Image " which allows the features used by our de-tector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small num-ber of critical visual features from a larger set and yields extremely efficient classifiers[6]. The third contribution is a method for combining increasingly more complex classi-fiers in a " cascade " which allows background regions of the image to be quickly discarded while spending more compu-tation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guar-antees that discarded regions are unlikely to contain the ob-ject of interest. In the domain of face detection the system yields detection rates comparable to the best previous sys-tems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differenc-ing or skin color detection.},
author = {Viola, Paul and Jones, Michael},
booktitle = {Accepted Conference on Computer Vision and Pattern Regognition},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viola, Jones - 2001 - Rapid Object Detection using a Boosted Cascade of Simple Features.pdf:pdf},
title = {{Rapid Object Detection using a Boosted Cascade of Simple Features}},
year = {2001}
}
@article{Zivkovic2004,
abstract = {Background subtraction is a common computer vision task. We analyze the usual pixel-level approach. We de-velop an efficient adaptive algorithm using Gaussian mix-ture probability density. Recursive equations are used to constantly update the parameters and but also to simulta-neously select the appropriate number of components for each pixel.},
author = {Zivkovic, Zoran},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zivkovic - 2004 - Improved Adaptive Gaussian Mixture Model for Background Subtraction.pdf:pdf},
journal = {Proceedings of the 17th International Conference on Pattern Recognition},
title = {{Improved Adaptive Gaussian Mixture Model for Background Subtraction}},
year = {2004}
}
@article{Zivkovic,
abstract = {We analyze the computer vision task of pixel-level background subtraction. We present recursive equations that are used to constantly update the parameters of a Gaussian mixture model and to simultaneously select the appropriate number of components for each pixel. We also present a simple non-parametric adaptive density estimation method. The two methods are compared with each other and with some previously proposed algorithms.},
author = {Zivkovic, Zoran and {Van Der Heijden}, Ferdinand},
doi = {10.1016/j.patrec.2005.11.005},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zivkovic, Van Der Heijden - 2005 - Efficient adaptive density estimation per image pixel for the task of background subtraction.pdf:pdf},
journal = {Pattern Recognition Letters},
keywords = {Background subtraction,Gaussian mixture model,Non-parametric density estimation,On-line density estimation},
number = {7},
pages = {773--780},
title = {{Efficient adaptive density estimation per image pixel for the task of background subtraction}},
volume = {27},
year = {2005}
}
@inproceedings{Dalal,
abstract = {We study the question of feature sets for robust visual ob-ject recognition, adopting linear SVM based human detec-tion as a test case. After reviewing existing edge and gra-dient based descriptors, we show experimentally that grids of Histograms of Oriented Gradient (HOG) descriptors sig-nificantly outperform existing feature sets for human detec-tion. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping de-scriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
author = {Dalal, Navneet and Triggs, Bill},
booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2005. CVPR 2005.},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dalal, Triggs - 2005 - Histograms of Oriented Gradients for Human Detection.pdf:pdf},
title = {{Histograms of Oriented Gradients for Human Detection}},
year = {2005}
}
@article{David2015,
author = {Layne, Ryan},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Layne - 2015 - Real-world Human Re-identification Attributes and Beyond.pdf:pdf},
title = {{Real-world Human Re-identification: Attributes and Beyond}},
year = {2015}
}
@inproceedings{Jungling,
abstract = {In this paper, we address the task of appearance based person reidentification in infrared image sequences. While common approaches for appearance based person reidenti-fication in the visible spectrum acquire color histograms of a person, this technique is not applicable in infrared for ob-vious reasons. To tackle the more difficult problem of per-son reidentification in infrared, we introduce an approach that relies on local image features only and thus is com-pletely independent of sensor specific features which might be available only in the visible spectrum. Our approach fits into an Implicit Shape Model (ISM) based person de-tection and tracking strategy described in previous work. Local features collected during tracking are employed for person reidentification while the generalizing appearance codebook used for person detection serves as structuring element to generate person signatures. By this, we gain an integrated approach that allows for fast online model gen-eration, a compact representation, and fast model match-ing. Since the model allows for a joined representation of appearance and spatial information, no complex represen-tation models like graph structures are needed. We evaluate our person reidentification approach on a subset of the CA-SIA infrared dataset.},
author = {J{\"{u}}ngling, Kai and Arens, Michael},
booktitle = {Seventh IEEE International Conference on Advanced Video and Signal Based Surveillance Local},
doi = {10.1109/AVSS.2010.75},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/J{\"{u}}ngling, Arens - 2010 - Local Feature Based Person Reidentification in Infrared Image Sequences.pdf:pdf},
title = {{Local Feature Based Person Reidentification in Infrared Image Sequences}},
year = {2010}
}
@article{opencv_library,
author = {Bradski, G},
journal = {Dr. Dobb's Journal of Software Tools},
keywords = {bibtex-import},
title = {{The OpenCV Library}},
year = {2000}
}
@book{Minichino2015,
author = {Minichino, Joe and Howse, Joseph},
edition = {Second edi},
isbn = {978-1-78528-384-0},
publisher = {PACKT Publishing},
title = {{Learning OpenCV 3 Computer Vision with Python}},
year = {2015}
}
@article{Huang,
abstract = {We define a new image feature called the color correlogram and use it for image indexing and comparison. This feature distills the spatial correlation of colors, and is both effective and inexpensive for content-based image retrieval. The correlogram robustly tolerates large changes in appearance and shape caused by changes in viewing positions, camera zooms, etc. Experimental evidence suggests that this new feature outperforms not only the traditional color histogram method but also the recently proposed histogram refinement methods for image indexing/retrieval},
author = {{Jing Huang} and Kumar, S.R. and Mitra, Mandar and {Wei-Jing Zhu} and Zabih, Ramin},
doi = {10.1109/CVPR.1997.609412},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jing Huang et al. - 1994 - Image Indexing using Color Correlograms.pdf:pdf},
isbn = {0-8186-7822-4},
issn = {0378-2697},
journal = {Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
number = {3-4},
pages = {762--768},
title = {{Image Indexing using Color Correlograms}},
url = {http://link.springer.com/10.1007/BF00984664{\%}5Cnhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=609412},
volume = {191},
year = {1994}
}
@article{Zhang2015,
abstract = {In a video surveillance network, it is always required to track and recognize people when they move through the environment. This paper presents a novel re-identification method for multiple-people using feature selection with sparsity. By using the multiple-shot approach, each of appearance models is created in this method. The human body is divided into five parts form which the features of color, height, gradient were extracted respectively. Our appearance model is represented by linear regression method. Experimental results show that our appearance model is robust and attain a high precision rate and processing performance.},
author = {Zhang, Dongping and Li, Yanjie and Xu, Jiao and Shen, Ye},
doi = {10.14257/ijhit.2015.8.1.03},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2015 - Multiple-shot People Re-identify based on Feature Selection with Sparsity.pdf:pdf},
issn = {1738-9968},
journal = {International Journal of Hybrid Information Technology},
keywords = {feature selection,multiple-shot,people re-identify,sparsity},
number = {1},
pages = {27--34},
title = {{Multiple-shot People Re-identify based on Feature Selection with Sparsity}},
url = {http://dx.doi.org/10.14257/ijhit.2015.8.1.03},
volume = {8},
year = {2015}
}
@article{Thakoor,
abstract = {Person reidentification is a problem of recognizing a person across non-overlapping camera views. Pose variations, illumination condi-tions, low resolution images, and occlusion are the main challenges encountered in reidentification. Due to the uncontrolled environment in which the videos are captured, people could appear in different poses and due to which the appearance of a person could vary sig-nificantly. The walking direction of a person can provide a good estimation of their pose. Therefore, in this paper, we propose a rei-dentification system which adaptively selects an appropriate distance metric based on context of walking direction using reinforcement learning. Though experiments, we show that such a dynamic strat-egy outperforms static strategy learned or designed offline.},
author = {Thakoor, Ninad and Bhanu, Bir},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thakoor, Bhanu - 2016 - Selective Experience Replay in Reinforcement Learning for Re-Identification.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {Index Terms— Reinforcement Learning,Reidentification},
title = {{Selective Experience Replay in Reinforcement Learning for Re-Identification}},
year = {2016}
}
@article{Huanga,
abstract = {This work proposes a novel person re-identification method based on Hierarchical Bipartite Graph Matching. Because human eyes observe person appearance roughly first and then goes further into the details gradually, our method abstracts person image from coarse to fine granularity, and finally into a three layer tree structure. Then, three bipartite graph match-ing methods are proposed for the matching of each layer be-tween the trees. At the bottom layer Non-complete Bipartite Graph matching is proposed to collect matching pairs among small local regions. At the middle layer Semi-complete Bi-partite Graph matching is used to deal with the problem of spatial misalignment between two person bodies. Complete Bipartite Graph matching is presented to refine the ranking result at the top layer. The effectiveness of our method is val-idated on the CAVIAR4REID and VIPeR datasets, and com-petitive results are achieved on both datasets.},
author = {Huang, Yan and Sheng, Hao and Xiong, Zhang},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Sheng, Xiong - 2016 - Person Re-Identification Based on Hierarchical Bipartite Graph Matching.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {Index Terms— person re-identification,bi-partite graph matching,cross views},
title = {{Person Re-Identification Based on Hierarchical Bipartite Graph Matching}},
year = {2016}
}
@article{DewanFahimNoorZhuLi2016,
author = {{Dewan Fahim Noor, Zhu Li}, Abhishek Nagar},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dewan Fahim Noor, Zhu Li - 2016 - Robust Object Re-Identification with Grassmann Subspace Feature for Key Points Aggregations.pdf:pdf},
journal = {ICIP 2016},
title = {{Robust Object Re-Identification with Grassmann Subspace Feature for Key Points Aggregations}},
year = {2016}
}
@article{Yao,
abstract = {Metric learning is an effective method for person re-identifi-cation. It utilizes latent factors to find a suitable space for measuring distances. In general, a small number of factors are not powerful enough to match the pedestrians while a large number of factors cause high computational cost. In this paper, to balance this trade-off, a novel diversity regular-ized distance metric learning method is proposed. For feature representation, the local discriminative features are extracted from the source image and an adjacency maximal constraint is developed to handle the misaligned issue. Then a diversity regularizer is used to learn a metric by making the latent fac-tors uncorrelated so that a small amount of latent factors can preserve effectiveness in measuring distances while reducing the computational burden. Our experimental results show that the proposed method with a small amount of factors can ob-tain comparative or even better performance compared to the state-of-art methods.},
author = {Yao, Wenbin and Weng, Zhenyu and Zhu, Yuesheng},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yao, Weng, Zhu - 2016 - Diversity Regularized Metric Learning for Person Re-Identification.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {Index Terms— Person re-identification,adjacency maximal constraint,diversity regularization,metric learning},
title = {{Diversity Regularized Metric Learning for Person Re-Identification}},
year = {2016}
}
@article{Li,
abstract = {Matching specific persons across scenes, known as per-son re-identification, is an important yet unsolved computer vision problem. Feature representation and metric learning are two fundamental factors in person re-identification. How-ever, current person re-identification methods, which use sin-gle handcrafted feature with corresponding metric, could be not powerful enough when facing illumination, viewpoint and pose variations. Thus it inevitably produces suboptimal rank-ing lists. In this paper, we propose incorporating multiple features with metrics to build weak learners, and aggregate the base ranking lists by AdaBoost Ranking. Experiments on two commonly used datasets, VIPeR and CUHK01, show that our proposed approach greatly improves recognition rates over the state-of-the-art methods.},
author = {Li, Zhaoju and Han, Zhenjun and Ye, Qixiang},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Han, Ye - 2016 - Person Re-Identification via AdaBoost Ranking Ensemble.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {AdaBoost,Base Model,Index Terms— Person Re-identification,Ranking},
title = {{Person Re-Identification via AdaBoost Ranking Ensemble}},
year = {2016}
}
@article{Gaoa,
abstract = {The problem of person re-identification, identifying the same person appeared in different camera views, is an important and challenging task in computer vision that has high poten-tial application in areas like visual surveillance. In this paper we introduce a new feature fusion strategy for person re-identification that combines low-level Weighted Histograms of Overlapping Stripes (WHOS) features with mid-level color name descriptors and we adopt KISSME algorithm for per-son matching. Experiments on several public person re-identification datasets (VIPeR, i-LIDS and CAVIAR4REID) demonstrate that our approach achieves much better results compared with other state-of-the-art approaches.},
author = {Gao, Mu and Ai, Haizhou and Bai, Bo},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gao, Ai, Bai - 2016 - A Feature Fusion Strategy for Person Re-Identification.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {Index Terms— Person re-identification,feature fusion,metric learning},
title = {{A Feature Fusion Strategy for Person Re-Identification}},
year = {2016}
}
@article{Zhu,
abstract = {Associating groups of people across non-overlapping cam-era views is an important but unsolved problem. Com-pared with the similar person re-identification task, group re-identification introduces some new challenges, such as significant deformation in uncontrolled directions, great intra-group occlusions and so on. In this paper, we propose a novel patch matching based framework for group re-identification. Discriminative salience channels are learned to filter out highly unreliable and non-informative patch matches between two group images, while retain true matches undergoing ap-pearance variations. The resulting candidate correspondences are further explored by the proposed consistent matching process, which prefers coherent matches in true group image pairs. The effectiveness of our approach is validated on two group re-identification datasets: ZeCSS and i-LIDS MCTS. It outperforms state-of-the-art methods on both datasets.},
author = {Zhu, Feng and Chu, Qi and Yu, Nenghai},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Chu, Yu - 2016 - Consistent Matching Based on Boosted Salience Channels for Group Re-Identification.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {Index Terms— Group re-identification,consistent matching,salience chan-nels},
title = {{Consistent Matching Based on Boosted Salience Channels for Group Re-Identification}},
year = {2016}
}
@inproceedings{Gao,
abstract = {This paper proposes an effective Temporally Aligned Pooling Representation (TAPR) for video-based person re-identification. To extract the motion information from a sequence, we pro-pose to track the superpixels of the lowest portions of human. To perform temporal alignment of videos, we propose to select the " best " walking cycle from the noisy motion in-formation according to the intrinsic periodicity property of walking persons, that is fitted sinusoid in our implementa-tion. To describe the video data in the selected walking cycle, we first divide the cycle into several segments according to the sinusoid, and then describe each segment by temporal-ly aligned pooling. Extensive experimental results on the public datasets demonstrate the effectiveness of the proposed method compared with the state-of-the-art approaches.},
author = {Gao, Changxin and Wang, Jin and Liu, Leyuan and Yu, Jin-Gang and Sang, Nong},
booktitle = {2016 IEEE International Conference on Image Processing (ICIP)},
doi = {10.1109/ICIP.2016.7533168},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gao et al. - 2016 - Temporally aligned pooling representation for video-based person re-identification.pdf:pdf},
isbn = {978-1-4673-9961-6},
keywords = {Index Terms— Person re-identification,superpixel,temporally aligned pooling,walking cycle},
number = {61271328},
pages = {4284--4288},
title = {{Temporally aligned pooling representation for video-based person re-identification}},
url = {http://ieeexplore.ieee.org/document/7533168/},
year = {2016}
}
@article{Wang,
abstract = {The difficult acquisition of labeled data and the misalignment of local matching are major obstacles to apply person re-identification in real scenarios. To alleviate these problems, we propose an unsupervised method, called locality-constrained Earth Mover's Distance (LC-EMD), to learn the optimal measure between image pairs. Specifically, Gaussian mixture models (GMMs) are learned as signatures. By imposing locality constraints, LC-EMD can naturally achieve partial matching between Gaussian components. Moreover, LC-EMD has the analytical solution which can be efficiently computed. Experiments on two public datasets demonstrate LC-EMD is robust to misalignment and performs better than other unsupervised methods.},
author = {Wang, Dan and Yan, Canxiang and Shan, Shiguang and Chen, Xilin},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2016 - Unsupervised Person Re-Identification with Locality-Constrained Earth Mover's Distance.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {Distance learning,Gaussian mixture model,Index Terms—Identification of persons},
title = {{Unsupervised Person Re-Identification with Locality-Constrained Earth Mover's Distance}},
year = {2016}
}
@inproceedings{Liu,
abstract = {Video-based person re-identification has become a hot topic in the field of research on computer vision and intelligent surveillance, which is more robust to the variations in a per-son's appearance than single-shot based methods and involves space-time information. However, the most existing spatio-temporal features have been proposed for action recognition that they mainly focus on the exact spatial changes over time. Unlike action recognition, pedestrians captured in person re-identification problem show similar and cyclic walking ac-tivities. The essential spatio-temporal information for person re-identification is the statistical information over time. In this paper, we propose a novel spatio-temporal feature, namely Fast Adaptive Spatio-Temporal 3D feature (FAST3D), for video-based person re-identification. The feature is able to extract the statistical motion information based on densely computed multi-direction gradients and an adaptive fusion process. We evaluate our method on two challenging datasets and the experimental results show the effectiveness and effi-ciency of the proposed feature.},
author = {Liu, Zheng and Chen, Jiaxin and Wang, Yunhong},
booktitle = {ICIP},
doi = {10.1109/ICIP.2016.7533170},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Chen, Wang - 2016 - A fast adaptive spatio-temporal 3D feature for video-based person re-identification.pdf:pdf},
isbn = {978-1-4673-9961-6},
keywords = {Index Terms— Person re-identification,efficient computation,relevance metric learning,spatio-temporal feature},
number = {1},
pages = {4294--4298},
title = {{A fast adaptive spatio-temporal 3D feature for video-based person re-identification}},
url = {http://ieeexplore.ieee.org/document/7533170/},
year = {2016}
}
@article{Tahboub,
abstract = {Person re-identification is the process of recognizing a person across a network of cameras with non-overlapping fields of view. In this paper we present an unsupervised multi-shot approach based on a patch-based dynamic appearance model. We use deformable graph matching for person re-identification using histograms of color and texture as features of nodes. Each graph model spans multiple im-ages and each node is a local patch in the shape of a rectangle. We evaluate our proposed method on publicly available PRID 2011 and iLIDS-VID databases.},
author = {Tahboub, Khalid and Delgado, Blanca and Delp, Edward J},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tahboub, Delgado, Delp - 2016 - Person Re-Idnetification using a Patch-Based Appearance Model.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {Index Terms— person re-identification,patch-based appearance model},
title = {{Person Re-Idnetification using a Patch-Based Appearance Model}},
year = {2016}
}
@article{Wanga,
abstract = {Most existing person re-identification (ReID) methods as-sume the availability of extensively labelled cross-view per-son pairs and a closed-set scenario (i.e. all the probe people exist in the gallery set). These two assumptions significantly limit their usefulness and scalability in real-world applica-tions, particularly with large scale camera networks. To overcome the limitations, we introduce a more challenging yet realistic ReID setting termed OneShot-OpenSet-ReID, and propose a novel Regularised Kernel Subspace Learning model for ReID under this setting. Our model differs sig-nificantly from existing ReID methods due to its ability of effectively learning cross-view identity-specific information from unlabelled data alone, and its flexibility of naturally accommodating pairwise labels if available.},
author = {Wang, Hanxiao and Zhu, Xiatian and Xiang, Tao and Gong, Shaogang},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2016 - Towards Unsupervised Open-Set Person Re-Identification.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {Index Terms— Person Re-identification,Kernelisation,Open-set Recog-nition,Unsupervised Subspace Learning},
title = {{Towards Unsupervised Open-Set Person Re-Identification}},
year = {2016}
}
@article{Mirmahboub,
abstract = {Human re-identification is still a challenging task due to the human pose and illumination variations. Nowadays, surveil-lance cameras with high frame rate are capable of capturing several consecutive frames from each person. Multi-shot im-ages provide richer information of the target person compared to a single-shot image. They, however, produce a high cost of information redundancy which may degrade the performance of re-identification systems. In this paper, we propose a novel framework that combines sparse coding and manifold con-straints to extract discriminative information from multi-shot images of one pedestrian for person re-identification across a set of non-overlapped surveillance cameras. The evaluation over two standard multi-shot datasets shows very competitive accuracy of our framework against the state-of-the-art.},
author = {Mirmahboub, Behzad and Kiani, Hamed and Bhuiyan, Amran and Perina, Alessandro and Zhang, Baochang and Bue, Alessio Del and Murino, Vittorio},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirmahboub et al. - 2016 - Person Re-Identification using Sparse Representation with Manifold Constraints.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {Index Terms— Person Re-identification,Manifold Constraint,Sparse Repre-sentation},
title = {{Person Re-Identification using Sparse Representation with Manifold Constraints}},
year = {2016}
}
@inproceedings{Prates,
abstract = {The automation of surveillance systems is important to allow real-time analysis of critical events, crime investigation and pre- vention. A crucial step in the surveillance systems is the person re-identification (Re-ID) which aims at maintaining the identity of agents in non-overlapping camera networks. Most of the works in literature compare a test sample against the entire gallery, restrict- ing the scalability. We address this problem employing multiple in- dexing lists obtained by color name descriptors extracted from part- based models using our proposed Predominant Color Name (PCN) indexing structure. PCN is a flexible indexing structure that relates features to gallery images without the need of labelled training im- ages and can be integrated with existing supervised and unsuper- vised person Re-ID frameworks. Experimental results demonstrate that the proposed approach outperforms indexation based on unsu- pervised clustering methods such as k-means and c-means. Further- more, PCN reduces the computational efforts with a minimum per- formance degradation. For instance, when indexing 50{\%} and 75{\%} of the gallery images, we observed a reduction in AUC curve of 0.01 and 0.08, respectively, when compared to indexing the entire gallery.},
author = {Prates, Raphael and Dutra, Cristianne R S and Schwartz, William Robson},
booktitle = {Proc. IEEE International Conference on Image Processing (ICIP'16)},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prates, Dutra, Schwartz - 2016 - Predominant color name indexing structure for person re-identification.pdf:pdf},
keywords = {Person re-identification,color names,inverted lists,surveillance scalability,visual dictionaries},
pages = {1--5},
title = {{Predominant color name indexing structure for person re-identification}},
year = {2016}
}
@article{Syed,
abstract = {In this paper, we propose a new Multi-kernel Metric Learn-ing (MKML) approach to enhance the performance of per-son re-identification using adaptive weighted Multi-kernel. The intuition behind our approach is that different features, i.e., low-level and middle-level features, have different nature and thus discriminating capability, utilizing different kernel-s could map these features into sub-spaces, which helps to improve the discrimination among features. The kernels are combined with an adaptive weighting strategy to get an effi-cient kernel space. The Fisher Discriminant Analysis (FDA) is used to learn the metric in the learned weighted kernels s-pace that enhances the robustness of metric to discriminate among classes. Experiments on two challenging person re-identification datasets, i.e., VIPeR and CUHK01, demonstrat-ed that our approach is effective.},
author = {Syed, Muhammad Adnan and Jiao, Jianbin},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Syed, Jiao - 2016 - Multi-Kernel Metric Learning for Person Re-Identification.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {Index Terms— Person Re-identification,Metric Learning,Multi-kernel Learning},
title = {{Multi-Kernel Metric Learning for Person Re-Identification}},
year = {2016}
}
@article{Chen,
abstract = {Most of the existing works on person re-identification have focused on improving matching rate at top ranks. Few ef-forts are devoted to address the problem of efficient storage and fast search for person re-identification. In this paper, we investigate the prevailing hashing method, originally designed for large scale image retrieval, for fast person re-identification with efficient storage. We propose a nov-el hashing approach, namely Distance Metric Learning to Discrete Hashing (DMLDH), which jointly learns a discrim-inative projection via metric learning to alleviate cross-view variations, and a hashing function for discriminative binary coding by minimizing inner-class Hamming distances and maximizing inter-class Hamming distances. To deal with the formulated non-convex optimization problem, we develop an alternative iteration algorithm by solving several subproblem-s with analytical solutions. Experimental results on bench-marks demonstrate that the proposed method outperforms the state-of-the-art hashing approaches.},
author = {Chen, Jiaxin and Wang, Yunhong and Wu, Rui},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Wang, Wu - 2016 - Person Re-Identification by Distance Metirc Learning to Discrete Hashing.pdf:pdf},
journal = {2016 IEEE International Conference on Image Processing},
keywords = {Efficient Storage and Fast Search,Hashing,Index Terms— Person Re-identification,Metric Learn-ing},
title = {{Person Re-Identification by Distance Metirc Learning to Discrete Hashing}},
year = {2016}
}
@book{Aghajan2009,
abstract = {ABSTRACT$\backslash$nIn recent years, camera networks have been widely employed in several application domains, such as surveillance, ambient intelligence and video conferencing. The integration of heterogeneous sensors can provide complementary and redundant information that when fused to visual cues allows the system to obtain an enriched and more robust scene interpretation. We discuss possible architectures and algorithms, showing, through system examples, the benefits of the combination of other sensor typologies for camera network-based applications.},
author = {Aghajan, Hamid and Cavallaro, Andrea and Dore, Alessio and Pinasco, Matteo and Regazzoni, Carlo S.},
booktitle = {Multi-Camera Networks},
doi = {10.1016/B978-0-12-374633-7.00011-2},
isbn = {9780123746337},
keywords = {Heterogeneous sensor networks,architecture design,fusion algorithms,multimedia applications},
pages = {213--237},
title = {{Multi-Camera Networks}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123746337000112},
year = {2009}
}
@inproceedings{Wu2012,
author = {Wu, Yang and Minoh, Michihiko and Mukunoki, Masayuki and Li, Wei and Lao, Shihong},
booktitle = {Proceedings - International Conference on Advanced Video and Signal-Based Surveillance},
doi = {10.1109/AVSS.2012.21},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2012 - Collaborative sparse approximation for multiple-shot across-camera person re-identification.pdf:pdf},
isbn = {9780769547978},
keywords = {Camera network,Collaborative representation,Person re-identification,Set-based recognition,Sparse representation},
month = {sep},
pages = {209--214},
publisher = {IEEE},
title = {{Collaborative sparse approximation for multiple-shot across-camera person re-identification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6328018},
year = {2012}
}
@article{Chu2014,
author = {Chu, Chun-Te and Hwang, Jenq-Neng},
doi = {10.1109/TCSVT.2014.2302516},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chu, Hwang - 2014 - Fully Unsupervised Learning of Camera Link Models for Tracking Humans Across Nonoverlapping Cameras.pdf:pdf},
issn = {1051-8215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Camera link model,Cameras,Color,Estimation,Histograms,Image color analysis,Training,Unsupervised learning,brightness,brightness transfer function,camera link models,camera network,cameras,deterministic annealing,estimation method,estimation theory,feature fusion weights,fully unsupervised learning,holistic color features,image colour analysis,image texture,multiple cues,multiple-camera tracking,multiple-camera tracking system,nonoverlapping cameras,nonoverlapping view,nonoverlapping views,object tracking,optimal model solutions,optimisation,optimization problem,region color features,region mapping matrix,region matching weights,region texture features,small-scale real-world camera network,systematic integration,temporal features,tracked humans,training data,training stage,transfer function matrices,transition time distribution,unsupervised learning,unsupervised scheme},
month = {jun},
number = {6},
pages = {979--994},
publisher = {IEEE},
title = {{Fully Unsupervised Learning of Camera Link Models for Tracking Humans Across Nonoverlapping Cameras}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6727542},
volume = {24},
year = {2014}
}
@article{YiminWang2014,
author = {Wang, Yimin and Hu, Ruimin and Liang, Chao and Zhang, Chunjie and Leng, Qingming},
doi = {10.1109/TCSVT.2014.2305519},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2014 - Camera compensation using a feature projection matrix for person reidentification.pdf:pdf},
isbn = {9781479900152},
issn = {10518215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Person re-identification,feature projection matrix,non-overlapping camera tracking},
month = {aug},
number = {8},
pages = {1350--1361},
publisher = {IEEE},
title = {{Camera compensation using a feature projection matrix for person reidentification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6739115},
volume = {24},
year = {2014}
}
@inproceedings{Martinel2016,
author = {Martinel, Niki and Foresti, Gian Luca and Micheloni, Christian},
booktitle = {IEEE Transactions on Cybernetics},
doi = {10.1109/TCYB.2016.2568264},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martinel, Foresti, Micheloni - 2016 - Person Reidentification in a Distributed Camera Network Framework.pdf:pdf},
issn = {21682267},
keywords = {Bandwidth,Cameras,Distance vector routing,Feature extraction,Measurement,Network topology,Probes,Routing,distributed camera network,person reidentification},
pages = {1--12},
publisher = {IEEE},
title = {{Person Reidentification in a Distributed Camera Network Framework}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7479516},
year = {2016}
}
@inproceedings{Padole2010,
author = {Padole, Chandrashekhar N. and Alexandre, Luis A.},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops},
doi = {10.1109/CVPRW.2010.5543226},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Padole, Alexandre - 2010 - Wigner distribution based motion tracking of human beings using thermal Imaging.pdf:pdf},
isbn = {978-1-4244-7029-7},
keywords = {Humans,Tracking,Wigner distribution,data association,false object detections,image motion analysis,image segmentation,image sequences,image threshold,infrared imaging,motion tracking,thermal imaging},
month = {jun},
pages = {9--14},
publisher = {IEEE},
title = {{Wigner distribution based motion tracking of human beings using thermal Imaging}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5543226},
year = {2010}
}
@inproceedings{Konigs2013,
abstract = {This work presents a tracking system that is tailored towards the needs of small mobile robots. It does not rely on person motion estimation in image space because of unpredictable camera movement while the robot traverses non-flat ground. Additionally it is fast enough to process 5 to 10 frames per second which allows interactive applications. The robustness of the tracking system is improved using fused visible spectrum and thermal images. This reduces false positives and enables the system to work in extreme light conditions. Experiments are conducted on both indoor and outdoor data. Outdoor data was recorded at different temperatures and with a moving robot.},
author = {Koenigs, Achim and Schulz, Dirk},
booktitle = {2013 IEEE International Symposium on Safety, Security, and Rescue Robotics},
doi = {10.1109/SSRR.2013.6719337},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koenigs, Schulz - 2013 - Fast Visual People Tracking using a Feature-Based People Detector and Thermal Imaging.pdf:pdf},
isbn = {978-1-4799-0879-0},
issn = {2374-3247},
keywords = {Cameras,Detectors,Feature extraction,Robot vision systems,Robustness,Tracking,extreme light conditions,fast visual people tracking,feature-based people detector,image fusion,image space,infrared imaging,mobile robots,motion estimation,object detection,object tracking,person motion estimation,robot vision,small mobile robots,thermal image fusion,thermal imaging,visible spectrum fusion},
month = {oct},
pages = {1--6},
publisher = {IEEE},
title = {{Fast Visual People Tracking using a Feature-Based People Detector and Thermal Imaging}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6719337},
year = {2013}
}
@inproceedings{Coutts2014,
author = {Coutts, Fraser K. and Marshall, Stephen and Murray, Paul},
booktitle = {2014 22nd European Signal Processing Conference (EUSIPCO)},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Coutts, Marshall, Murray - 2014 - Human detection and tracking through temporal feature recognition.pdf:pdf},
issn = {2219-5491},
keywords = {Algorithm design and analysis,Automated human tracking,Feature extraction,Principal component analysis,Robustness,Support vector machines,Target tracking,feature extraction,human detection,human tracking,object detection,object tracking,person specific time varying signatures,spatial tracking methods,temporal characteristic recognition,temporal feature recognition,temporal signature recognition,thermal video,video signal processing},
pages = {2180--2184},
publisher = {IEEE},
title = {{Human detection and tracking through temporal feature recognition}},
year = {2014}
}
@inproceedings{Ciric2013,
abstract = {This paper describes a system for real-time robust segmentation of human in a thermal image used for supervisory control of mobile robot platform. The main goal was to enable mobile robot platform to recognize the person in indoor environment, and to localize it with accuracy high enough to allow adequate human-robot interaction. The developed computationally intelligent control algorithm enables robust and reliable human tracking by mobile robot platform. The core of the recognition methods proposed is intelligent segmentation and classification of detected regions of interests in every frame acquired by thermal vision camera. Advanced intelligent segmentation algorithm is based on improved fuzzy closed-loop colour region segmentation. This segmentation algorithm enables autonomous functioning of robot system in cluttered environments. The classifier determines whether the segmented object is human or not based on features extracted from the processed thermal image. With this approach a person can be detected independently from current light conditions and in situations where no skin colour is visible. However, variation in temperature across same objects, air flow with different temperature gradients, person overlap while crossing each other and reflections, put challenges in thermal imaging and will have to be handled intelligently in order to obtain the efficient performance from motion tracking system. Presented research in this field includes making tracking system more robust and reliable by using the computational intelligence.},
author = {Ciric, Ivan and Cojbasic, Zarko and Nikolic, Vlastimir and Antic, Dragan},
booktitle = {2013 11th International Conference on Telecommunications in Modern Satellite, Cable and Broadcasting Services, TELSIKS 2013},
doi = {10.1109/TELSKS.2013.6704447},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ciric et al. - 2013 - Computationally intelligent system for thermal vision people detection and tracking in robotic applications.pdf:pdf},
isbn = {9781479909025},
keywords = {Computational intelligence,Human tracking,Robot vision,Thermal vision},
month = {oct},
pages = {587--590},
publisher = {IEEE},
title = {{Computationally intelligent system for thermal vision people detection and tracking in robotic applications}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6704447},
volume = {2},
year = {2013}
}
@inproceedings{Kwak2015,
author = {Kwak, Joon Young and Ko, Byoungchul and Nam, Jae Yeal},
booktitle = {Proceedings - 2015 IEEE Winter Conference on Applications of Computer Vision, WACV 2015},
doi = {10.1109/WACV.2015.13},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kwak, Ko, Nam - 2015 - Multi-person tracking based on body parts and online random ferns learning of thermal images.pdf:pdf},
isbn = {9781479966820},
keywords = {BRF,Computer vision,Conferences,body parts,boosted random ferns,concatenated feature vectors,estimation theory,image filtering,infrared imaging,learning (artificial intelligence),multiperson tracking,object tracking,observational likelihood estimation,occlusion-check algorithm,online RF learning,online random ferns learning,online training,particle filtering (numerical methods),particle filters,particle weighting,person detection,robust tracking model,thermal imaging},
month = {jan},
pages = {41--46},
publisher = {IEEE},
title = {{Multi-person tracking based on body parts and online random ferns learning of thermal images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7045867},
year = {2015}
}
@article{Prince2013,
abstract = {This modern treatment of computer vision focuses on learning and inference in probabilistic models as a unifying theme. It shows how to use training data to learn the relationships between the observed image data and the aspects of the world that we wish to estimate, such as the 3D structure or the object class, and how to exploit these relationships to make new inferences about the world from new image data. With minimal prerequisites, the book starts from the basics of probability and model fitting and works up to real examples that the reader can implement and modify to build useful vision systems. Primarily meant for advanced undergraduate and graduate students, the detailed methodological presentation will also be useful for practitioners of computer vision. - Covers cutting-edge techniques, including graph cuts, machine learning, and multiple view geometry. - A unified approach shows the common basis for solutions of important computer vision problems, such as camera calibration, face recognition, and object tracking. - More than 70 algorithms are described in sufficient detail to implement. - More than 350 full-color illustrations amplify the text. - The treatment is self-contained, including all of the background mathematics. - Additional resources at www.computervisionmodels.com.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Prince, Dr Simon J. D.},
doi = {10.1016/S1474-4422(13)70064-4},
eprint = {arXiv:1011.1669v3},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prince - 2013 - Computer Vision Models, Learning, and Inference.pdf:pdf},
isbn = {9781107011793},
issn = {14744422},
journal = {The Lancet Neurology},
number = {4},
pages = {335},
pmid = {2013185901},
title = {{Computer Vision: Models, Learning, and Inference}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1474442213700644},
volume = {12},
year = {2013}
}
@article{Szeliski2010,
abstract = {As humans, we perceive the three-dimensional structure of the world around us with apparent ease. However, despite all of the recent advances in computer vision research, the dream of having a computer interpret an image at the same level as a two-year old remains elusive. Why is computer vision such a challenging problem, and what is the current state of the art?Computer Vision: Algorithms and Applications explores the variety of techniques commonly used to analyze and interpret images. It also describes challenging real-world applications where vision is being successfully used, both for specialized applications such as medical imaging and fun consumer-level tasks such as image editing and stitching, which students can apply to their own personal photos and videos.More than just a source of "recipes", this text/reference also takes a scientific approach to basic vision problems, formulating physical models of the imaging process before inverting this process to produce the best possible descriptions of a scene. Exercises are presented throughout the book, with a heavy emphasis on testing algorithms.Suitable for either an undergraduate or a graduate-level course in computer vision, this textbook focuses on basic techniques that work under real-world conditions and encourages students to push their creative boundaries.Dr. Richard Szeliski has over twenty years' experience in computer vision research, most notably at Digital Equipment Corporation and Microsoft.},
author = {Szeliski, Richard},
doi = {10.1007/978-1-84882-935-0},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szeliski - 2010 - Computer Vision Algorithms and Applications.pdf:pdf},
isbn = {1848829345},
issn = {10636919},
journal = {Computer},
pages = {832},
pmid = {16259003},
title = {{Computer Vision : Algorithms and Applications}},
url = {http://research.microsoft.com/en-us/um/people/szeliski/book/drafts/szelski{\_}20080330am{\_}draft.pdf},
volume = {5},
year = {2010}
}
@book{Maggio2011,
abstract = {Video Tracking provides a comprehensive treatment of the fundamental aspects of algorithm and application development for the task of estimating, over time, the position of objects of interest seen through cameras. Starting from the general problem definition and a review of existing and emerging video tracking applications, the book discusses popular methods, such as those based on correlation and gradient-descent. Using practical examples, the reader is introduced to the advantages and limitations of deterministic approaches, and is then guided toward more advanced video tracking solutions, such as those based on the Bayes' recursive framework and on Random Finite Sets. Key features: Discusses the design choices and implementation issues required to turn the underlying mathematical models into a real-world effective tracking systems. Provides block diagrams and simil-code implementation of the algorithms. Reviews methods to evaluate the performance of video trackers – this is identified as a major problem by end-users. The book aims to help researchers and practitioners develop techniques and solutions based on the potential of video tracking applications. The design methodologies discussed throughout the book provide guidelines for developers in the industry working on vision-based applications. The book may also serve as a reference for engineering and computer science graduate students involved in vision, robotics, human-computer interaction, smart environments and virtual reality programmes},
author = {Maggio, Emilio and Cavallaro, Andrea},
booktitle = {Book},
doi = {10.1002/9780470974377},
isbn = {978-0-470-74964-7},
keywords = {dblp},
pages = {I----XXV, 1----266},
title = {{Video Tracking - Theory and Practice.}},
url = {http://doi.wiley.com/10.1002/9780470974377{\%}5Cnhttp://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470749644.html;{\%}5Cnhttp://www.bibsonomy.org/bibtex/2236605cbe0dec216dfd746ae049c74a4/dblp},
year = {2011}
}
@article{Kundegorski2015,
abstract = {Target tracking complexity within conventional video imagery can be fundamentally attributed to the am-biguity associated with actual 3D scene position of a given tracked object in relation to its observed position in 2D image space. Recent work, within thermal-band infrared imagery, has tackled this challenge head on by returning to classical photogrammetry as a means of recovering the true 3D position of pedestrian tar-gets. A key limitation in such approaches is the as-sumption of posture – that the observed pedestrian is at full height stance within the scene. Whilst prior work has shown the effects of statistical height vari-ation to be negligible, variations in the posture of the target may still pose a significant source of potential er-ror. Here we present a method that addresses this issue via the use of Support Vector Machine (SVM) regres-sion based pedestrian posture estimation operating on Histogram of Orientated Gradient (HOG) feature de-scriptors. Within an existing tracking framework, we demonstrate improved target localization that is inde-pendent of variations in target posture (i.e. behaviour) and within the statistical error bounds of prior work for pedestrian height posture varying from 0.4-2.4m over a distance to target range of 7-30m.},
author = {Kundegorski, M E and Breckon, T P},
doi = {10.1117/12.2195050},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kundegorski, Breckon - 2015 - Posture estimation for improved photogrammetric localization of pedestrians in monocular infrared imagery.pdf:pdf},
isbn = {9781628418620},
issn = {1996756X},
journal = {Optics and Photonics for Counterterrorism, Crime Fighting and Defence Toulouse, France},
title = {{Posture estimation for improved photogrammetric localization of pedestrians in monocular infrared imagery}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84958214503{\&}partnerID=40{\&}md5=c7f250f4a3d62b8ff163ac2cff4d2e5e},
volume = {9652},
year = {2015}
}
@article{Kundegorski2013,
author = {Kundegorski, Mikolaj E. and Breckon, Toby P.},
doi = {10.1117/12.2065673},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kundegorski, Breckon - 2014 - A Photogrammetric Approach for Real-time 3D Localization and Tracking of Pedestrians in Monocular Infrared.pdf:pdf},
isbn = {9789898565471},
journal = {In Proc. SPIE Optics and Photonics for Counterterrorism, Crime Fighting and Defence, SPIE, pp. 1-16, 2014.},
keywords = {2,3d pedes- approach for,4,a means of recovering,and classification techniques,as,classification and localiza-,intelligent target reporting,of pedes-,passive target positioning,pedestrian detection,people detection,scene,sensor networks,temporal fil- target detection,temporal fusion,tering,the detection,the true 3d position,thermal imaging,thermal target tracking,trian targets within the,we present a real-time},
title = {{A Photogrammetric Approach for Real-time 3D Localization and Tracking of Pedestrians in Monocular Infrared Imagery}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2065673{\%}5Cnhttp://www.pages.drexel.edu/{~}zz57/VISAPP 2013.pdf},
year = {2014}
}
@incollection{Layne,
abstract = {Automated person re-identification using only visual information from public-space CCTV video is challenging for many reasons, such as poor resolution or challenges involved in dealing with camera calibration. More critical still, the majority of clothing worn in public spaces tends to be non-discriminative and there- fore of limited disambiguation value. Most re-identification techniques developed so far have relied on low-level visual-feature matching approaches that aim to re- turn matching gallery detections earlier in the ranked list of results. However, for many applications an initial probe image may not be available, or a low-level fea- ture representation may not be sufficiently invariant to viewing condition changes as well as being discriminative for re- identification. In this chapter, we showhowmid- level “semantic attributes” can be computed for person description.We further show how this attribute-based description can be used in synergy with low-level feature descriptions to improve re-identification accuracy when an attribute-centric distance measure is employed. Moreover, we discuss a “zero-shot” scenario in which a visual probe is unavailable but re-identification can still be performed with user-provided semantic attribute description.},
author = {Layne, Ryan and Hospedales, Timothy M and Gong, Shaogang},
booktitle = {Person Re-Identification},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Layne, Hospedales, Gong - 2014 - Attributes-based Re-Identification.pdf:pdf},
pages = {93--121},
title = {{Attributes-based Re-Identification}},
year = {2014}
}
@article{Mogelmose2013,
author = {Mogelmose, Andreas and Bahnsen, Chris and Moeslund, Thomas B. and Clapes, Albert and EscalerA, Sergio},
doi = {10.1109/CVPRW.2013.52},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mogelmose et al. - 2013 - Tri-modal person re-identification with rgb, depth and thermal features.pdf:pdf},
isbn = {9780769549903},
issn = {21607508},
journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
keywords = {Depth Features,Multi-modal data,Reidentification,Thermal Features},
pages = {301--307},
title = {{Tri-modal person re-identification with rgb, depth and thermal features}},
year = {2013}
}
@incollection{Gong2014,
author = {Gong, Shaogang and Cristani, Marco and Loy, Chen Change and Hospedales, Timothy M},
booktitle = {Person Re-Identification},
doi = {10.1007/978-1-4471-6296-4_1},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gong et al. - 2014 - The Re-Identification Challenge.pdf:pdf},
isbn = {978-1-4471-6295-7},
pages = {1--21},
title = {{The Re-Identification Challenge}},
url = {http://www.eecs.qmul.ac.uk/{~}sgg/papers/GongEtAl{\_}REIDChallenge2013.pdf},
year = {2014}
}
@article{Layne2014,
abstract = {Person re-identification is a crucial capability underpinning many applications of public-space video surveillance. Recent studies have shown the value of learning semantic attributes as a discriminative representation for re-identification. However, existing attribute representations do not generalise across camera deployments. Thus, this strategy currently requires the prohibitive effort of annotating a vector of person attributes for each individual in a large training set -- for each given deployment/dataset. In this paper we take a different approach and automatically discover a semantic attribute ontology, and learn an effective associated representation by crawling large volumes of internet data. In addition to eliminating the necessity for per-dataset annotation, by training on a much larger and more diverse array of examples this representation is more view-invariant and generalisable than attributes trained at conventional small scales. We show that these automatically discovered attributes provide a valuable representation that significantly improves re-identification performance on a variety of challenging datasets.},
author = {Layne, Ryan and Hospedales, Tim and Gong, Shaogang},
doi = {10.5244/C.28.1},
file = {:home/tom/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Layne, Hospedales, Gong - 2014 - Re-id Hunting Attributes in the Wild.pdf:pdf},
isbn = {1-901725-52-9},
journal = {Proceedings of the British Machine Vision Conference 2014},
title = {{Re-id: Hunting Attributes in the Wild}},
url = {http://www.bmva.org/bmvc/2014/papers/paper042/index.html},
year = {2014}
}
