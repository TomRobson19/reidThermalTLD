#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{durhampaper}


\title{Deep Learning Enabled Open World Thermal Re-Identification}
\student{T.A. Robson}
\supervisor{T.P. Breckon}
\degree{MEng Computer Science}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman times
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style agsm
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date true
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 2cm
\bottommargin 2cm
\headheight 2cm
\headsep 2cm
\footskip 1cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard

\lang english
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
maketitle
\end_layout

\end_inset


\end_layout

\begin_layout Abstract

\series bold
Context/Background
\end_layout

\begin_layout Abstract
Although use of thermal imagery currently poses significant advantages for
 24/7 surveillance in terms of the visibility of targets under all environmental
 conditions, a key limitation is the lack of colour information.
 Person re-identification across multiple cameras is a key research problem
 within the domain of visual surveillance and a key challenge for the future
 deployment of thermal sensing as an autonomous sensor technology.
 Many current approaches to the problem rely on colour features 
\begin_inset CommandInset citation
LatexCommand cite
key "Gong2014"

\end_inset

.
 We have previously attempted to use a set of similar features to solve
 the thermal re-identification problem with little success 
\begin_inset CommandInset citation
LatexCommand cite
key "Robson2017"

\end_inset

, and are now exploring alternatives.
 
\end_layout

\begin_layout Abstract

\series bold
Aims
\end_layout

\begin_layout Abstract
The aim of this project is to develop a system that would build upon and
 extend the range of existing thermal image detection, tracking and classificati
on approaches.
 The first step for this is to be able to detect a person within thermal
 imagery in real time, distinguish a person from other objects and track
 a person moving through a scene in real time.
 We would then use a Siamese Convolutional Neural Network to determine if
 a pair of images contained the same person or two different people.
 This architecture has been chosen as it enables us to deploy the system
 of any camera system with any human targets, rather than simply to train
 and test in a closed world on the same set of people, as many previous
 approaches have 
\begin_inset CommandInset citation
LatexCommand cite
key "Zheng2016"

\end_inset

.
 This means that we are aiming to solve the open world re-identification
 problem.
\end_layout

\begin_layout Abstract

\series bold
Method
\end_layout

\begin_layout Abstract

\series bold
Results
\end_layout

\begin_layout Abstract

\series bold
Conclusions
\end_layout

\begin_layout Abstract
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Abstract

\series bold
Keywords: 
\series default
Deep Learning, Siamese Network, Computer Vision, Person Re-Identification,
 Re-ID, Person Tracking, Thermal Imagery, Thermal Video
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
A fundamental task for a distributed multi-camera surveillance system is
 to associate people across different camera views at different locations
 and times 
\begin_inset CommandInset citation
LatexCommand cite
key "Gong2014"

\end_inset

.
 This is referred to as the person re-identification problem 
\begin_inset CommandInset citation
LatexCommand cite
key "Gong2014"

\end_inset

 and is an interesting and important problem within the field of computer
 vision.
 From the previous work, we can see that a substantial amount of research
 that has been done on person re-identification, mainly revolving around
 the use of features or attributes of a person 
\begin_inset CommandInset citation
LatexCommand cite
key "Layne"

\end_inset

.
 However, much of this relies on the visible spectrum, with attributes of
 the form “red shirt” 
\begin_inset CommandInset citation
LatexCommand cite
key "Layne"

\end_inset

.
 However, in the modern world, thermal imagery is often used for 24/7 surveillan
ce when varying environmental conditions are present.
 Therefore, it is important that an effective re-identification system is
 developed to utilise this area of surveillance, as this problem is yet
 to be effectively solved.
\end_layout

\begin_layout Standard
There are many potential applications for this technology, but the most
 important in the modern world would be to support human intelligence organisati
ons.
 The surveillance data that a system like this can provide would be critical
 for crime-prevention, forensic analysis, and counter-terrorism activities
 in both civilian and governmental agencies alike.
 While this is currently widely used by human operators, these operators
 have to be trained, which offsets the utility of this approach with training
 and staffing costs.
 The implementation of an automated re-identification system is therefore
 of great interest, as it would be very useful in supporting these human
 operators and enabling them to achieve better results more efficiently.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Example-of-Thermal"

\end_inset

 shows five different views of the same person that our features must be
 able to re-identify as being the same person.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/Screenshot from running20140319.webm.png
	scale 12

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/Screenshot from running20140319.webm - 2.png
	scale 12

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/Screenshot from running20140319.webm - 3.png
	scale 12

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/Screenshot from walking20140319.webm.png
	scale 12

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/Screenshot from walking20140319.webm - 1.png
	scale 12

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Example-of-Thermal"

\end_inset

Several frames showing the same person that our system must re-identify
 as the same person
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement R
overhang 0in
width "40col%"
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/open vs closed.png
	scale 30

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
The difference between closed world (a) and open world (b) re-identification
 systems, from 
\begin_inset CommandInset citation
LatexCommand cite
key "Zheng2016"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:openVsClosed"

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Whilst thermal imagery has many advantages, it is not able to identify colour,
 making features that rely on colour useless.
 Therefore, alternative features are required to facilitate re-identification.
 In our previous work in 
\begin_inset CommandInset citation
LatexCommand cite
key "Robson2017"

\end_inset

, we attempted to use features that a human would think were distinctive
 enough to facilitate re-identification.
 This had only limited success.
 Since our work in 
\begin_inset CommandInset citation
LatexCommand cite
key "Robson2017"

\end_inset

, the attention of the researchers of re-identification has shifted to deep
 learning based solutions, as shall be discussed in more detail in the Related
 Work section.
 These deep learning approaches can be split into two categories: closed
 world, where the system is trained and tested on the same set of people
 from a pre defined dataset, and open world, where the system is trained
 to learn what makes people different, so it can be applied to any dataset
 of people.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:openVsClosed"

\end_inset

 shows the difference between these two possible approaches to deep learning
 enabled re-identification.
\end_layout

\begin_layout Standard
In order to improve the performance and runtime of our new approach, we
 are replacing the Kalman filter used in 
\begin_inset CommandInset citation
LatexCommand cite
key "Robson2017"

\end_inset

 with an implementation of the Track-Learn-Detect (TLD) tracker, originally
 proposed by the authors of 
\begin_inset CommandInset citation
LatexCommand cite
key "Kalal2010"

\end_inset

.
 The aim here is to ensure that we do not have to pass every frame to the
 neural network, but instead, when a person has been identified, they can
 then be tracked for as long as they remain unobscured in the frame, and
 continue to be labelled as the same person.
\end_layout

\begin_layout Subsection
Aims of the Project
\end_layout

\begin_layout Standard
The intent of this project is to develop a system that can utilise an open
 world deep neural network, paired with a real time person detection system
 and TLD tracker, to solve the thermal re-identification problem, and improve
 on the performance of state of the art solutions, including our own previous
 work 
\begin_inset CommandInset citation
LatexCommand cite
key "Robson2017"

\end_inset

.
 
\end_layout

\begin_layout Subsection
Achievements of the Project
\end_layout

\begin_layout Section
Related Work
\end_layout

\begin_layout Subsection
Feature-Based Attempts at Re-Identification
\end_layout

\begin_layout Standard
Re-identification in colour is a well researched area, particularly using
 distinctive features for this purpose.
 Many of these methods are discussed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Gong2014"

\end_inset

, and have been widely researched and understood, so research has moved
 on to explore more complex methods.
 An important part of the current state of the art in this area is camera
 network layout and topology, as explored in 
\begin_inset CommandInset citation
LatexCommand cite
key "Martinel2016"

\end_inset

.
 Here, the technique of distance vector routing is employed to get an idea
 of the relative locations of the cameras, enabling the system to prioritise
 the people seen most recently by the closest camera, as these are most
 likely to be correct.
 This is done by first analysing the overlap between cameras, and then computing
 distance vectors and probabilities of going from one camera to another,
 reducing the time complexity of the re-identification process in the majority
 of cases.
 
\end_layout

\begin_layout Standard
The work in 
\begin_inset CommandInset citation
LatexCommand cite
key "Chu2014"

\end_inset

 is on a similar theme to 
\begin_inset CommandInset citation
LatexCommand cite
key "Martinel2016"

\end_inset

, but assumes a non-overlapping camera system.
 Each camera has entry and exit zones from its field of view, and if a person
 can get from one camera field of view to another they are directly connected.
 The system can then create what is referred to as a camera link model,
 using a temporal, spatial and appearance relation between the entry and
 exit zones of the cameras.
 These paths are obtained from training data, but the system itself learns
 how to recognise people by attributes, and uses the training data to estimate
 where they are most likely to have gone after leaving a given camera field
 of view.
 
\end_layout

\begin_layout Standard
The authors of 
\begin_inset CommandInset citation
LatexCommand cite
key "YiminWang2014"

\end_inset

 propose a different method for feature based identification, using a feature
 projection matrix to project image features of one camera to the feature
 space of another, to effectively eliminate the difference of feature distributi
ons between the two cameras.
 This feature projection matrix is obtained through supervised learning.
 The proposed method aims to use a simple gradient descent algorithm to
 accelerate and optimise the re-identification process by compensating for
 the inconsistency of feature distributions captured by different cameras.
 
\end_layout

\begin_layout Standard
The work in 
\begin_inset CommandInset citation
LatexCommand cite
key "Wu2012"

\end_inset

 emphasises the importance of making good use of all images and video frames
 captured of a target.
 The system proposed here creates a gallery of images of known individuals,
 with more images increasing the accuracy of the system.
 When a gallery exists for a target, this is referred to as multi-shot re-identi
fication, and single-shot re-identification when only one image is available
 in both the query and the gallery.
 For multi-shot re-identification, the authors propose to use geometric
 distance in another way by collaboratively approximating the query sets
 using all galleries, a method known as Collaborative Sparse Approximation.
 
\end_layout

\begin_layout Standard
Another approach, taken by the authors of 
\begin_inset CommandInset citation
LatexCommand cite
key "Liu2014"

\end_inset

, relies not only on extracting a set of features to use to compare people,
 but also on determining which of these features is the most discriminative
 for each person individually on the fly.
 This is achieved through the use of a random forest classifier, and functions
 well in an open world setting.
 However, since the time of publication of this paper, the state of the
 art of this area has moved on to deep learning.
 
\end_layout

\begin_layout Standard
Our own previous attempt at thermal re-identification in 
\begin_inset CommandInset citation
LatexCommand cite
key "Robson2017"

\end_inset

 attempted to use features that a human would consider useful to re-identify
 people, such as an approximation of the shape of the target, an analysis
 of their gait and a measure of where each person's thermal 'hotspots' were.
 This performed resonably well for some features, but its inaccuracy in
 many situations led us to explore an alternative approach, using deep learning,
 based on the current state of the art in the area.
 
\end_layout

\begin_layout Subsection
Use of Deep Learning for Re-Identification
\end_layout

\begin_layout Standard
The use of deep learning to facilitate re-identification has been the driving
 force in the research community in this area in recent times.
 As our ability to train deeper and deeper networks on larger and larger
 datasets has increased, largely thanks to modern improvements in graphics
 hardware, these approaches become more and more relevant and powerful.
 As before, much of this research is focused on the colour spectrum.
 The work of 
\begin_inset CommandInset citation
LatexCommand cite
key "Matsukawa2017"

\end_inset

 shows us how a combination of deep learning and human recognisable features
 can be used for re-identification.
 This works by training a neural network to recognise certain features that
 the authors consider to be discriminative.
 The result from the network is an ordered vector for the presence or absence
 of these features.
 However, as our previous work showed that we were unable to choose suitably
 descriminitive features for thermal re-identification, we will not be able
 to follow this approach.
 
\end_layout

\begin_layout Standard
Much of the rest of the previous deep learning work is split into open world
 and closed world.
 The work of 
\begin_inset CommandInset citation
LatexCommand cite
key "Zheng2016"

\end_inset

 presents a useful comparison between these two problems, as shown in Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:openVsClosed"

\end_inset

.
 They refer to the closed world problem as Identification and the open world
 problem as Verification, with the justification that in close world, the
 aim is to identify which of a given set of people the target is, where
 as in open world, the aim is to verify whether two targets are the same
 or not.
 These two approaches differ greatly in terms of input method, feature extractio
n and the loss function used.
 The authors of 
\begin_inset CommandInset citation
LatexCommand cite
key "Zheng2016"

\end_inset

 conclude, as we have, that the open world problem is more relevant to real
 world applications.
 
\end_layout

\begin_layout Standard
A solution to the open world problem is attempted in 
\begin_inset CommandInset citation
LatexCommand cite
key "Zhang2014"

\end_inset

.
 The authors aim to combine feature learning and re-identification into
 one framework, which is a deep siamese CNN with an SVM placed on top of
 the network, after the last layer, to attempt open world re-identification.
 The results of this are promising for the potential use of such an architecture
, but fall short of the state of the art at time of writing.
 The apparent reason for this is overfitting to the dataset used to train
 the architecture, and the authors hypothesise that if they could use a
 dataset with wider variation of people, improved results could be achieved.
 As this work is several years old, we can hypothesise that with modern
 graphics hardware, this model could realistically be trained on a much
 larger and more varied dataset, which should improve the results.
 This hypothesis is backed up by the authors of 
\begin_inset CommandInset citation
LatexCommand cite
key "Ahmed2015"

\end_inset

, who have implemented architecture and trained on a larger dataset which
 consistently outperforms the state of the art at the time of its writing.
 
\end_layout

\begin_layout Standard
The work in 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang2016a"

\end_inset

 proposes a similar deep siamese CNN architecture, but also retains the
 single image representation.
 The purpose of this is to reduce the amount of computational work that
 must be done on both images together, as well as jointly optimising the
 single image representation and cross image representation for improved
 accuracy at a lower computational cost.
 The authors claim to outperform the majority of the state of the art methods
 at the time of writing.
 The work presented in 
\begin_inset CommandInset citation
LatexCommand cite
key "Chung2017"

\end_inset

 uses a pair of siamese CNNs, one to learn spatial information and the other
 to learn temporal information.
 These features are then weighted, as the authors claim that spatial features
 are more discriminative than temporal features.
 This method outperforms or shows comparable results to the existing best
 performing methods.
 The work in 
\begin_inset CommandInset citation
LatexCommand cite
key "Qian2017"

\end_inset

 is another siamese CNN with the particular aim of making it work for people
 represented at different scales.
 This would be an interesting addition to our work, but is currently out
 of scope for us.
 
\end_layout

\begin_layout Standard
The authors of 
\begin_inset CommandInset citation
LatexCommand cite
key "Almazan2018"

\end_inset

 do not propose a novel architecture as such, but instead propose a set
 of good practices that should be followed for effective re-identification,
 such as pre-training for identity classification, sufficiently large image
 resolution, state of the-art base architecture and dataset augmentation
 with difficult examples.
 We will endeavour to follow these guidelines in our work in this project
 wherever possible.
\end_layout

\begin_layout Subsection
TLD Tracker
\end_layout

\begin_layout Standard
The Track-Learn-Detect (TLD) tracker was first proposed by Zdenek Kalal
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "Kalal2010"

\end_inset

.
 The idea of this tracker is to break down the person tracking task into
 tracking, learning and detection.
 The tracker follows the object between frames.
 The detector corrects the tracker if necessary based on previous observations.
 The learning estimates detector’s errors and updates it to avoid these
 errors in the future.
 However, the main purpose of TLD is to be able to consistently follow the
 same object through as changing background, for example a car driving along
 a road being recorded from a helicopter.
 The authors have said that it performs sub optimally on varying targets
 such as people.
 During our early experimentation, we found that is was sufficiently capable
 of tracking a person through a single camera frame, but could not re-identify
 people accross multiple cameras, or even returning from behind an obstruction.
\end_layout

\begin_layout Subsection
Relation to this Project
\end_layout

\begin_layout Standard
In this project we use elements from many of the papers discussed in this
 section.
 The TLD tracker will be used simply for tracking a person for as long as
 they remain visible in one camera view.
 Whether this person has been previously observed by the system or not will
 be determined by an open world siamese CNN, with an architecture similar
 to the related work.
 We take inspiration from 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang2016a"

\end_inset

 and will extract the features of each individual image before comparison
 between them.
 However, many of these papers that propose such a network only show results
 when it is trained and tested on a specific dataset of still images.
 They do not integrate it with a tracking system to see how it can perform
 in the real world.
 Also, this previous work has all been done on colour imagery.
 Very little work has been done to try and solve the re-identification problem
 in thermal imagery, save for our own previous work 
\begin_inset CommandInset citation
LatexCommand cite
key "Robson2017"

\end_inset

.
 Therefore, the major research aim of our project, and where we are advancing
 the state of the art, is to see if such a network architecture can successfully
 be applied to thermal imagery, and whether it can perform effectively as
 a part of a full re-identification system in real time.
 
\end_layout

\begin_layout Section
Solution
\end_layout

\begin_layout Standard
Having established the problem that we want to solve, we will now break
 down the most important elements of our solution, giving an overview of
 the structure of our implementation and a description of the elements used.
\end_layout

\begin_layout Subsection
Implementation Structure and Tools Used
\end_layout

\begin_layout Standard
The implementation will begin by opening each video file, or live camera
 feed, and concurrently running the real time target detection code on these.
 Each time this code identifies a person that does not currently have a
 TLD tracker object associated with them, it compares this person to the
 other people that have been seen previously using the siamese CNN, and
 if they are deemed to be sufficiently similar to one of these people, then
 they are re-identified as the same person, else the system creates a new
 person object.
 Each of these person objects has an associated TLD tracker and set of previous
 observations, and these are used to facilitate the comparison between targets,
 and are updated each time the target is successfully identified.
 This continues frame by frame until the video file or camera feed ends,
 as shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Logic-of-our"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename Project Activity Diagram Fourth Year.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Logic-of-our"

\end_inset

Logic of our Re-Identification System
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Many of the computer vision techniques that will be described in the next
 section are complex to implement.
 Therefore, version 3 of the OpenCV library 
\begin_inset CommandInset citation
LatexCommand cite
key "opencv_library"

\end_inset

 has been used to allow us to use stable, well tested code.
 However, the implementation of TLD code in OpenCV is suboptimal, so we
 have used the existing open source multi-object implementation of TLD from
 
\begin_inset CommandInset citation
LatexCommand cite
key "Lutz2015"

\end_inset

.
 The neural network side of the project is written in Keras 
\begin_inset CommandInset citation
LatexCommand cite
key "chollet2015keras"

\end_inset

, using the Tensorflow backend.
 
\end_layout

\begin_layout Subsection
Real Time Person Detection
\end_layout

\begin_layout Standard
Before we can start concerning ourselves with deep learning based person
 re-identification, we must be able to identify whether a person is present
 in the image at all, so we have a region of interest to pass to the neural
 network, and so we can use TLD to track targets through single camera views.
 
\end_layout

\begin_layout Subsubsection
Background Subtraction
\end_layout

\begin_layout Standard
The first stage of this process is background subtraction from the static
 camera viewpoint.
 We use the Mixture of Gaussians (MoG) technique to facilitate this, taking
 inspiration from 
\begin_inset CommandInset citation
LatexCommand cite
key "Zivkovic2004,Zivkovic"

\end_inset

.
 This technique works by building up a background model over multiple camera
 frames, modelling each of the pixels using multiple Gaussians.
 Using a Gaussian over the last 
\begin_inset Formula $N$
\end_inset

 frames, where 
\begin_inset Formula $N$
\end_inset

 is given by a parameter specifying the rate at which the background model
 is updated, is far more memory efficient than storing all the pixel values
 across the entire video capture.
 This update rate is determined by the trade off between being fast enough
 to absorb objects that have become stationary into the background, and
 being slow enough to allow the detection of slow moving objects.
\end_layout

\begin_layout Standard
As the program runs through the video, during each new frame, a Gaussian
 for each pixel is evaluated using a simple heuristic to determine which
 is most likely to correspond to the background model.
 Pixels that do not match closely enough with these background Gaussians
 are classified as foreground elements, and added to a new image in the
 code.
 Once these foreground pixels are identified and built into a foreground
 mask, erosion and dilation image operators 
\begin_inset CommandInset citation
LatexCommand cite
key "solomonbreckon10fundamentals"

\end_inset

 are used to clean up these results.
 From here, we use the contour detection to find the connected components,
 and draw bounding boxes around these contours.
 
\end_layout

\begin_layout Subsubsection
Person Identification
\end_layout

\begin_layout Standard
Having identified the foreground objects, we must now determine whether
 they are people.
 The implementation uses Histogram of Oriented Gradients (HOG), discussed
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "Dalal"

\end_inset

.
 This method works by performing edge gradient calculation on the bounding
 box identified by the background subtractor.
 From here cell histograms are computed, with each of the histogram entries
 filled by gradient magnitudes.
 These histograms are then used to create overlapping block histograms of
 the adjacent cells.
 These block histograms are then concatenated to give a HOG descriptor,
 a high dimensional vector.
 This HOG descriptor is then passed to a pre-trained machine learning algorithm,
 in this case a Support Vector Machine (SVM).
 If this comes up with a positive identification, then it is classified
 as a person, and will be given an associated TLD tracker object.
 
\end_layout

\begin_layout Subsubsection
Person Tracking using Track-Learn-Detect
\end_layout

\begin_layout Standard
Once we know where the people are in the camera view, we can track their
 movement.
 We use the Track-Learn-Detect algorithm, originally proposed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Kalal2010"

\end_inset

.
 This algorithm was originally intended to facilitate the long term tracking
 of an unknown object in a video stream.
 The algorithm works by breaking down the person tracking task into tracking,
 learning and detection.
 The tracker follows the object between frames.
 The detector corrects the tracker if necessary based on previous observations.
 The learning estimates detector’s errors and updates it to avoid these
 errors in the future.
 In our early experimentation, we found that the learning part of this algorithm
 meant that it was attempting to perform re-identification when people left
 and re-entered a video stream, or appeared in a different one.
 Therefore, we had to cut some of the functionality out of TLD for this
 implementation, so that each object was deleted when it left the scene
 or became obstructed.
 This eliminated the miss-classifications that the limited re-identification
 capabilities of this algorithm were causing, enabling us to effectively
 track people across the scene, whilst using our neural network for the
 re-identification.
 
\end_layout

\begin_layout Standard
Therefore, in this implementation, each person currently present in any
 of the camera views has an associated TLD tracker object, which is created
 on the first HoG identification in this neighbourhood, and classified by
 the neural network.
 The tracker then follows this person through the frame until either the
 person leaves the frame or HoG is no longer getting a positive identification
 within the tracker.
 If either of these conditions occurs, the TLD object is deleted.
 In the case of no HoG identification being present, this indicated that
 the tracker has incorrectly predicted the position or rate of movement
 of the person, and has lost them.
 A new tracker will then be created to replace it in the next frame when
 HoG detects this person again.
 
\end_layout

\begin_layout Subsection
Deep Learning
\end_layout

\begin_layout Subsubsection
Network Architecture
\end_layout

\begin_layout Standard
Taking inspiration from the state of the art literature in the area of open
 world person re-identification, our network architecture is a Deep Siamese
 CNN.
 This means that the network is trained on pairs of images, and attempts
 to determine whether these images show the same person or a different person.
 The two networks which are each fed an image have exactly the same architecture
 and weights, as they are trained together.
 Our CNN consists of convolutional layers, pooling layers and fully connected
 layers.
 
\end_layout

\begin_layout Standard
The convolutional layers operate directly on the image to reduce the complexity
 of the input in a manner that is both meaningful and structured.
 This enables the network to have fewer neurons than a traditional fully
 connected feedforward network would have if operating on an image.
 This enables the convolutional neural network to be far deeper with fewer
 parameters.
 This resolves the vanishing or exploding gradients problem that would otherwise
 occur.
 
\end_layout

\begin_layout Standard
Pooling layers then down-sample their input, looking at a neighbourhood
 of pixels and, in the case of max pooling that we have used here, outputs
 the maximum.
 The aim of this is to provide robustness to the changes in the spatial
 location of features across the dataset and to reduce input dimensionality.
 This is also an effective tool to control overfitting, as it reduces the
 number of training parameters and ensures that it is the general regions
 where features are present that are learned, not the specific pixels of
 the images in the training set that they are present in.
 
\end_layout

\begin_layout Standard
Finally, we flatten the output of our last pooling layer to a single dimension
 and then pass it to a fully connected layer.
 The high dimensional vector output of this layer will be the representation
 of this image, and we will use the euclidean distances between these vectors
 to determine whether the inputs show the same person or different people.
 
\end_layout

\begin_layout Standard
At various stages of the network, we have some dropout layers.
 The purpose of dropout is to eliminate a proportion of the training data
 at each epoch to help to prevent overfitting, as the network is being trained
 on a different dataset each epoch.
 The goal is therefore to force the network to learn more robust features
 that are useful in conjunction with random subsets of the other neurons
 so that good performance is still achieved when some neurons are removed.
\end_layout

\begin_layout Standard
The loss function to be used for this network was proposed by the authors
 of 
\begin_inset CommandInset citation
LatexCommand cite
key "Hadsell2006"

\end_inset

.
 This paper defines a contrastive loss function, which maps high dimensional
 inputs to lower dimensional outputs, given distances between samples in
 its input space.
 These distances between samples are supplied by the euclidean distance.
 The formula for this function is given by equation (1) below, where Y is
 the label (0 or 1), m is the margin that determines the the maximum euclidean
 distance between two points that will influence the loss function.
 The purpose of this is to ensure that vastly different images do not have
 a disproportional effect on the learning outcome.
 D is the euclidean distance, which is defined here by equation (2) below,
 where X1 and X2 are the input images and F represents the feature vectors
 output by the siamese pair of identical CNNs.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
L=(1-Y)\frac{1}{2}(D)^{2}+Y\frac{1}{2}\{max(0,m-D)\}^{2}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
D=\sqrt{\{F(X1)-F(X2)\}^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The actual architecture chosen was two convolutional layers, a max pooling
 layer, a dropout layer, two convolutional layers, a max pooling layer,
 a dropout layer, a flatten layer, a dropout layer and a dense fully connected
 layer.
 The parameters for these layers such as the activation functions, the convoluti
onal kernel sizes, stride sizes, pooling width, dropout rates and size of
 the dense layer were all determined by an exhaustive grid search using
 the Hyperas library 
\begin_inset CommandInset citation
LatexCommand cite
key "Pumperla2017"

\end_inset

.
\end_layout

\begin_layout Standard
FIGURE HERE FROM TENSORBOARD ONCE FINALISED
\end_layout

\begin_layout Subsubsection
Training Dataset
\end_layout

\begin_layout Standard
The model was trained on the dataset collected for our previous work 
\begin_inset CommandInset citation
LatexCommand cite
key "Robson2017"

\end_inset

, as this contained video of multiple people, some similar and some greatly
 differing, from different views.
 The real time person detection system discussed previously was adapted
 into a data extraction system, where the identification of each person
 was performed by a key press, rather than the neural network.
 Each successive frame of each person was then saved to a file, labelled
 with which person it showed.
 The size of these files was fixed at 258x128, to ensure that the size of
 the file had no effect on the training.
 This meant that the system was trained on varying resolutions, as some
 regions of interest had to be enlarged, and others had to be shrunk.
 This would help the ability of the system to re-identify at different distances
 away from the cameras.
 
\end_layout

\begin_layout Standard
These files were then formed into positive and negative pairs of images,
 where positive pairs were both images of the same person and negative pairs
 were not.
 We took care to ensure we had an equal number of positive and negative
 pairs, giving a balanced dataset.
 These pairs were assigned binary labels, 1 for positive pairs and 0 for
 negative pairs.
 We then applied some data augmentation to the images, following the advice
 of 
\begin_inset CommandInset citation
LatexCommand cite
key "Almazan2018"

\end_inset

.
 This involved applying a random transformation to each image, effectively
 doubling the size of the dataset.
 The possible transformations consisted of a horizontal flip, small shifts
 vertically or horizontally, and a small rotation.
 The aim of this is to introduce more variation into our dataset and enable
 it to cope better with difficult real world situations.
 
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Subsection
The Dataset
\end_layout

\begin_layout Standard
The data used to evaluate the features that have been implemented here was
 gathered with three cameras at Durham University.
 The cameras and their fields of view are arranged as they are in figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Setup-of-Cameras"

\end_inset

(a), with the cameras labelled as camera 
\begin_inset Formula $\alpha$
\end_inset

, 
\begin_inset Formula $\beta$
\end_inset

 and 
\begin_inset Formula $\gamma$
\end_inset

 respectively, and their fields of view shown by the matching coloured lines.
 The images seen by the cameras are shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Setup-of-Cameras"

\end_inset

(b).
 The dataset contains five people.
 
\end_layout

\begin_layout Standard
CHANGE THIS FIGURE WHEN ALL RUNS CORRECTLY
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../../../old/thirdYearWork/Project/reidThermal/General/datasetDiagram.png
	scale 34

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../../../old/thirdYearWork/Project/reidThermal/General/viewpoints.png
	scale 16

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Setup-of-Cameras"

\end_inset

Position and field of view of the cameras used to record our data 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
The Deep Learning System
\end_layout

\begin_layout Standard
Train/test results, tensorboard grpahs, TNSE plots, excel plots of distances.
\end_layout

\begin_layout Subsection
Re-Identification Performance
\end_layout

\begin_layout Section
Evaluation
\end_layout

\begin_layout Standard
We will now evaluate the strengths, weaknesses and limitations of the research
 that has been presented here.
 
\end_layout

\begin_layout Subsection
Real Time Person Detection System
\end_layout

\begin_layout Subsection
Deep Learning System
\end_layout

\begin_layout Subsection
Re-Identification System
\end_layout

\begin_layout Subsection
Appraisal of Project Organisation
\end_layout

\begin_layout Section
Conclusion 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "My Collection"
options "bibtotoc,plain"

\end_inset


\end_layout

\end_body
\end_document
