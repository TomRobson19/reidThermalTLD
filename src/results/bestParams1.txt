>>> Imports:
#coding=utf-8

try:
    import numpy as np
except:
    pass

try:
    import random
except:
    pass

try:
    from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping
except:
    pass

try:
    from keras.datasets import mnist
except:
    pass

try:
    from keras.models import Sequential, Model
except:
    pass

try:
    from keras.layers import Dense, Dropout, Input, Lambda, Conv2D, MaxPooling2D, Activation, Flatten, Reshape, Permute
except:
    pass

try:
    from keras.optimizers import RMSprop
except:
    pass

try:
    from keras import backend as K
except:
    pass

try:
    import os
except:
    pass

try:
    import cv2
except:
    pass

try:
    from hyperas.utils import eval_hyperopt_space
except:
    pass

try:
    import tensorflow as tf
except:
    pass

try:
    import sklearn
except:
    pass

try:
    from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
except:
    pass

try:
    from keras.wrappers.scikit_learn import KerasClassifier
except:
    pass

try:
    from scipy.stats import randint as sp_randint
except:
    pass

try:
    from scipy.stats import uniform as sp_uniform
except:
    pass

try:
    from hyperas import optim
except:
    pass

try:
    from hyperas.distributions import choice, uniform, conditional
except:
    pass

try:
    from hyperopt import Trials, STATUS_OK, tpe
except:
    pass

>>> Hyperas search space:

def get_space():
    return {
        'Conv2D': hp.choice('Conv2D', [16,32,64]),
        'pool_size': hp.choice('pool_size', [1,2,3,4,5,6,7,8,9,10]),
        'activation': hp.choice('activation', ['relu', 'tanh']),
        'Conv2D_1': hp.choice('Conv2D_1', [16,32,64]),
        'pool_size_1': hp.choice('pool_size_1', [1,2,3,4,5,6,7,8,9,10]),
        'activation_1': hp.choice('activation_1', ['relu', 'tanh']),
        'pool_size_2': hp.choice('pool_size_2', [1,2,3,4,5,6,7,8,9,10]),
        'Conv2D_2': hp.choice('Conv2D_2', [16,32,64]),
        'pool_size_3': hp.choice('pool_size_3', [1,2,3,4,5,6,7,8,9,10]),
        'activation_2': hp.choice('activation_2', ['relu', 'tanh']),
        'Conv2D_3': hp.choice('Conv2D_3', [16,32,64]),
        'pool_size_4': hp.choice('pool_size_4', [1,2,3,4,5,6,7,8,9,10]),
        'activation_3': hp.choice('activation_3', ['relu', 'tanh']),
        'pool_size_5': hp.choice('pool_size_5', [1,2,3,4,5,6,7,8,9,10]),
        'Dense': hp.choice('Dense', [16,32,64,128, 256]),
        'activation_4': hp.choice('activation_4', ['relu', 'tanh']),
    }

>>> Functions
   1: def euclidean_distance(vects):
   2:     x, y = vects
   3: 
   4:     #return K.cast(K.less(K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True)),0.5),"float32")
   5: 
   6:     return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))
   7: 
   8: def eucl_dist_output_shape(shapes):
   9:     shape1, shape2 = shapes
  10:     return (shape1[0], 1)
  11: 
  12: def contrastive_loss(y_true, y_pred):
  13:     '''Contrastive loss from Hadsell-et-al.'06
  14:     http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf
  15:     '''
  16:     margin = 1 
  17:     return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))
  18: 
  19: def calc_accuracy(labels, predictions):
  20:     '''accuracy function for compilation'''
  21:     return K.mean(K.equal(labels, K.cast(K.less(predictions,0.5),"float32")))
  22: 
  23: def create_pairs(x, digit_indices):
  24:     '''Positive and negative pair creation.
  25:     Alternates between positive and negative pairs.
  26:     '''
  27:     pairs = []
  28:     labels = []
  29:     n = min([len(digit_indices[d]) for d in range(8)]) - 1
  30:     for d in range(8):
  31:         for i in range(n):
  32:             z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]
  33:             pairs += [[x[z1], x[z2]]]
  34:             inc = random.randrange(1, 8)
  35:             dn = (d + inc) % 8
  36:             z1, z2 = digit_indices[d][i], digit_indices[dn][i]
  37:             pairs += [[x[z1], x[z2]]]
  38:             labels += [1, 0]
  39:     return np.array(pairs), np.array(labels)
  40: 
  41: 
>>> Data
   1: 
   2: 
   3: x_train = []
   4: x_test = []
   5: y_train = []
   6: y_test = []
   7: 
   8: image_dir = "people"
   9: img_groups = {}
  10: for person in os.listdir(image_dir): 
  11:     for img_file in os.listdir(image_dir + "/" + person):
  12:         if person in img_groups:
  13:             img_groups[person].append(img_file)
  14:         else:
  15:             img_groups[person]=[img_file]
  16: 
  17: for target in img_groups:
  18:     for img_file in img_groups[target]:
  19:         if int(target) < 8:
  20:             img = cv2.imread(os.path.join(image_dir, target, img_file))
  21:             img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
  22:             if np.random.random() < 0.8:
  23:                 x_train.append(img)
  24:                 y_train.append(int(target))
  25:             else:
  26:                 x_test.append(img)
  27:                 y_test.append(int(target))
  28: 
  29: x_train = np.array(x_train)
  30: x_test = np.array(x_test)
  31: y_train = np.array(y_train)
  32: y_test = np.array(y_test)
  33: 
  34: input_shape = (256, 128, 1)
  35: x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)
  36: x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)
  37: x_train = x_train.astype('float32')
  38: x_test = x_test.astype('float32')
  39: x_train /= 255
  40: x_test /= 255  
  41: 
  42: num_epochs = 50
  43: 
  44: # create training+test positive and negative pairs
  45: digit_indices = [np.where(y_train == i)[0] for i in range(8)]
  46: tr_pairs, tr_y = create_pairs(x_train, digit_indices)
  47: 
  48: digit_indices = [np.where(y_test == i)[0] for i in range(8)]
  49: te_pairs, te_y = create_pairs(x_test, digit_indices)
  50: 
  51: x_train = [tr_pairs[:, 0], tr_pairs[:, 1]]
  52: y_train = tr_y
  53: x_test = [te_pairs[:, 0], te_pairs[:, 1]]
  54: y_test = te_y
  55: 
  56: 
  57: 
>>> Resulting replaced keras model:

   1: def keras_fmin_fnct(space):
   2: 
   3:     input_shape = (256, 128, 1)
   4: 
   5:     input_main = Input(shape=input_shape, dtype='float32')
   6:     x = Conv2D(space['Conv2D'], space['pool_size'], padding='same', activation=space['activation'])(input_main)
   7:     x = Conv2D(space['Conv2D_1'], space['pool_size_1'], padding='same', activation=space['activation_1'])(x)
   8:     x = MaxPooling2D(pool_size=space['pool_size_2'])(x)
   9:     x = Dropout(0.25)(x)
  10: 
  11:     x = Conv2D(space['Conv2D_2'], space['pool_size_3'], padding='same', activation=space['activation_2'])(x)
  12:     x = Conv2D(space['Conv2D_3'], space['pool_size_4'], padding='same', activation=space['activation_3'])(x)
  13:     x = MaxPooling2D(pool_size=space['pool_size_5'])(x)
  14:     x = Dropout(0.25)(x)
  15: 
  16:     x = Flatten()(x)
  17:     x = Dense(space['Dense'], activation=space['activation_4'])(x)
  18: 
  19:     base_network = Model(inputs=input_main, outputs=x)
  20: 
  21:     input_a = Input(shape=input_shape)
  22:     input_b = Input(shape=input_shape)
  23: 
  24: 
  25:     # because we re-use the same instance `base_network`,
  26:     # the weights of the network
  27:     # will be shared across the two branches
  28:     processed_a = base_network(input_a)
  29:     processed_b = base_network(input_b)
  30: 
  31:     distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])
  32: 
  33: 
  34:     model = Model(inputs=[input_a, input_b], outputs=distance)
  35:     model.compile(loss=contrastive_loss, optimizer='adadelta', metrics=[calc_accuracy])
  36: 
  37:     model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=num_epochs, verbose=2)
  38: 
  39:     score, acc = model.evaluate(x_test, y_test, verbose=0)
  40:     print('Test accuracy:', acc)
  41: 
  42:     K.clear_session()
  43: 
  44:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}
  45: 
Train on 4976 samples, validate on 1312 samples
Epoch 1/50
 - 34s - loss: 0.2738 - calc_accuracy: 0.5096 - val_loss: 0.4494 - val_calc_accuracy: 0.5000
Epoch 2/50
 - 30s - loss: 0.2542 - calc_accuracy: 0.5215 - val_loss: 0.4109 - val_calc_accuracy: 0.5000
Epoch 3/50
 - 30s - loss: 0.2547 - calc_accuracy: 0.5187 - val_loss: 0.4255 - val_calc_accuracy: 0.5000
Epoch 4/50
 - 31s - loss: 0.2508 - calc_accuracy: 0.5356 - val_loss: 0.4134 - val_calc_accuracy: 0.5000
Epoch 5/50
 - 31s - loss: 0.2538 - calc_accuracy: 0.5135 - val_loss: 0.4218 - val_calc_accuracy: 0.5000
Epoch 6/50
 - 31s - loss: 0.2497 - calc_accuracy: 0.5404 - val_loss: 0.4086 - val_calc_accuracy: 0.5000
Epoch 7/50
 - 32s - loss: 0.2448 - calc_accuracy: 0.5621 - val_loss: 0.3913 - val_calc_accuracy: 0.5000
Epoch 8/50
 - 32s - loss: 0.2359 - calc_accuracy: 0.5922 - val_loss: 0.3528 - val_calc_accuracy: 0.5000
Epoch 9/50
 - 32s - loss: 0.2297 - calc_accuracy: 0.6111 - val_loss: 0.3512 - val_calc_accuracy: 0.5000
Epoch 10/50
 - 32s - loss: 0.2221 - calc_accuracy: 0.6369 - val_loss: 0.2684 - val_calc_accuracy: 0.5419
Epoch 11/50
 - 32s - loss: 0.2166 - calc_accuracy: 0.6590 - val_loss: 0.3138 - val_calc_accuracy: 0.5038
Epoch 12/50
 - 32s - loss: 0.2131 - calc_accuracy: 0.6652 - val_loss: 0.3616 - val_calc_accuracy: 0.5000
Epoch 13/50
 - 32s - loss: 0.2107 - calc_accuracy: 0.6644 - val_loss: 0.2532 - val_calc_accuracy: 0.5663
Epoch 14/50
 - 32s - loss: 0.2053 - calc_accuracy: 0.6744 - val_loss: 0.2693 - val_calc_accuracy: 0.5419
Epoch 15/50
 - 32s - loss: 0.2011 - calc_accuracy: 0.6907 - val_loss: 0.2204 - val_calc_accuracy: 0.6349
Epoch 16/50
 - 32s - loss: 0.1954 - calc_accuracy: 0.7022 - val_loss: 0.2457 - val_calc_accuracy: 0.5732
Epoch 17/50
 - 32s - loss: 0.1874 - calc_accuracy: 0.7213 - val_loss: 0.2061 - val_calc_accuracy: 0.6669
Epoch 18/50
 - 32s - loss: 0.1879 - calc_accuracy: 0.7126 - val_loss: 0.2664 - val_calc_accuracy: 0.5473
Epoch 19/50
 - 32s - loss: 0.1852 - calc_accuracy: 0.7182 - val_loss: 0.2304 - val_calc_accuracy: 0.6044
Epoch 20/50
 - 32s - loss: 0.1756 - calc_accuracy: 0.7424 - val_loss: 0.1995 - val_calc_accuracy: 0.6791
Epoch 21/50
 - 32s - loss: 0.1804 - calc_accuracy: 0.7367 - val_loss: 0.1877 - val_calc_accuracy: 0.7088
Epoch 22/50
 - 32s - loss: 0.1728 - calc_accuracy: 0.7446 - val_loss: 0.1821 - val_calc_accuracy: 0.7302
Epoch 23/50
 - 32s - loss: 0.1711 - calc_accuracy: 0.7510 - val_loss: 0.2296 - val_calc_accuracy: 0.5998
Epoch 24/50
 - 32s - loss: 0.1691 - calc_accuracy: 0.7540 - val_loss: 0.1919 - val_calc_accuracy: 0.7012
Epoch 25/50
 - 32s - loss: 0.1625 - calc_accuracy: 0.7631 - val_loss: 0.2166 - val_calc_accuracy: 0.6441
Epoch 26/50
 - 32s - loss: 0.1635 - calc_accuracy: 0.7619 - val_loss: 0.1990 - val_calc_accuracy: 0.6883
Epoch 27/50
 - 32s - loss: 0.1605 - calc_accuracy: 0.7685 - val_loss: 0.1770 - val_calc_accuracy: 0.7470
Epoch 28/50
 - 32s - loss: 0.1620 - calc_accuracy: 0.7693 - val_loss: 0.1973 - val_calc_accuracy: 0.6951
Epoch 29/50
 - 32s - loss: 0.1564 - calc_accuracy: 0.7759 - val_loss: 0.1997 - val_calc_accuracy: 0.6883
Epoch 30/50
 - 32s - loss: 0.1537 - calc_accuracy: 0.7852 - val_loss: 0.1822 - val_calc_accuracy: 0.7241
Epoch 31/50
 - 32s - loss: 0.1547 - calc_accuracy: 0.7822 - val_loss: 0.2300 - val_calc_accuracy: 0.6098
Epoch 32/50
 - 32s - loss: 0.1517 - calc_accuracy: 0.7868 - val_loss: 0.1755 - val_calc_accuracy: 0.7485
Epoch 33/50
 - 32s - loss: 0.1504 - calc_accuracy: 0.7942 - val_loss: 0.1765 - val_calc_accuracy: 0.7447
Epoch 34/50
 - 32s - loss: 0.1503 - calc_accuracy: 0.7874 - val_loss: 0.1795 - val_calc_accuracy: 0.7431
Epoch 35/50
 - 32s - loss: 0.1454 - calc_accuracy: 0.8008 - val_loss: 0.1709 - val_calc_accuracy: 0.7561
Epoch 36/50
 - 32s - loss: 0.1446 - calc_accuracy: 0.8004 - val_loss: 0.1918 - val_calc_accuracy: 0.7180
Epoch 37/50
 - 32s - loss: 0.1454 - calc_accuracy: 0.8004 - val_loss: 0.1872 - val_calc_accuracy: 0.7195
Epoch 38/50
 - 32s - loss: 0.1408 - calc_accuracy: 0.8103 - val_loss: 0.1704 - val_calc_accuracy: 0.7645
Epoch 39/50
 - 32s - loss: 0.1385 - calc_accuracy: 0.8115 - val_loss: 0.1593 - val_calc_accuracy: 0.7858
Epoch 40/50
 - 32s - loss: 0.1375 - calc_accuracy: 0.8129 - val_loss: 0.1675 - val_calc_accuracy: 0.7706
Epoch 41/50
 - 32s - loss: 0.1328 - calc_accuracy: 0.8230 - val_loss: 0.1625 - val_calc_accuracy: 0.7790
Epoch 42/50
 - 32s - loss: 0.1332 - calc_accuracy: 0.8260 - val_loss: 0.1641 - val_calc_accuracy: 0.7774
Epoch 43/50
 - 32s - loss: 0.1303 - calc_accuracy: 0.8270 - val_loss: 0.1530 - val_calc_accuracy: 0.7950
Epoch 44/50
 - 32s - loss: 0.1334 - calc_accuracy: 0.8209 - val_loss: 0.1502 - val_calc_accuracy: 0.8056
Epoch 45/50
 - 32s - loss: 0.1295 - calc_accuracy: 0.8296 - val_loss: 0.1624 - val_calc_accuracy: 0.7744
Epoch 46/50
 - 32s - loss: 0.1279 - calc_accuracy: 0.8340 - val_loss: 0.1514 - val_calc_accuracy: 0.8018
Epoch 47/50
 - 32s - loss: 0.1270 - calc_accuracy: 0.8350 - val_loss: 0.1424 - val_calc_accuracy: 0.8178
Epoch 48/50
 - 32s - loss: 0.1241 - calc_accuracy: 0.8432 - val_loss: 0.1401 - val_calc_accuracy: 0.8293
Epoch 49/50
 - 32s - loss: 0.1220 - calc_accuracy: 0.8483 - val_loss: 0.1575 - val_calc_accuracy: 0.7881
Epoch 50/50
 - 32s - loss: 0.1233 - calc_accuracy: 0.8382 - val_loss: 0.1402 - val_calc_accuracy: 0.8262
Test accuracy: 0.8262195121951219
Train on 4976 samples, validate on 1312 samples
Epoch 1/50
 - 12s - loss: 0.3021 - calc_accuracy: 0.4972 - val_loss: 0.4445 - val_calc_accuracy: 0.5000
Epoch 2/50
 - 10s - loss: 0.2754 - calc_accuracy: 0.4984 - val_loss: 0.4295 - val_calc_accuracy: 0.5000
Epoch 3/50
 - 10s - loss: 0.2684 - calc_accuracy: 0.5133 - val_loss: 0.4271 - val_calc_accuracy: 0.5000
Epoch 4/50
 - 10s - loss: 0.2763 - calc_accuracy: 0.5030 - val_loss: 0.4474 - val_calc_accuracy: 0.5000
Epoch 5/50
 - 10s - loss: 0.2774 - calc_accuracy: 0.5058 - val_loss: 0.4071 - val_calc_accuracy: 0.5000
Epoch 6/50
 - 10s - loss: 0.2673 - calc_accuracy: 0.5143 - val_loss: 0.3859 - val_calc_accuracy: 0.5000
Epoch 7/50
 - 10s - loss: 0.2611 - calc_accuracy: 0.5330 - val_loss: 0.3414 - val_calc_accuracy: 0.5000
Epoch 8/50
 - 10s - loss: 0.2591 - calc_accuracy: 0.5529 - val_loss: 0.3464 - val_calc_accuracy: 0.5000
Epoch 9/50
 - 10s - loss: 0.2508 - calc_accuracy: 0.5930 - val_loss: 0.2425 - val_calc_accuracy: 0.5877
Epoch 10/50
 - 10s - loss: 0.1983 - calc_accuracy: 0.6919 - val_loss: 0.1765 - val_calc_accuracy: 0.7302
Epoch 11/50
 - 10s - loss: 0.1773 - calc_accuracy: 0.7381 - val_loss: 0.1543 - val_calc_accuracy: 0.7995
Epoch 12/50
 - 10s - loss: 0.1599 - calc_accuracy: 0.7681 - val_loss: 0.1578 - val_calc_accuracy: 0.7790
Epoch 13/50
 - 10s - loss: 0.1516 - calc_accuracy: 0.7926 - val_loss: 0.1313 - val_calc_accuracy: 0.8148
Epoch 14/50
 - 10s - loss: 0.1376 - calc_accuracy: 0.8213 - val_loss: 0.1252 - val_calc_accuracy: 0.8430
Epoch 15/50
 - 10s - loss: 0.1333 - calc_accuracy: 0.8258 - val_loss: 0.1154 - val_calc_accuracy: 0.8620
Epoch 16/50
 - 10s - loss: 0.1288 - calc_accuracy: 0.8344 - val_loss: 0.1072 - val_calc_accuracy: 0.8704
Epoch 17/50
 - 10s - loss: 0.1187 - calc_accuracy: 0.8503 - val_loss: 0.1012 - val_calc_accuracy: 0.8864
Epoch 18/50
 - 10s - loss: 0.1140 - calc_accuracy: 0.8609 - val_loss: 0.1057 - val_calc_accuracy: 0.8758
Epoch 19/50
 - 10s - loss: 0.1120 - calc_accuracy: 0.8696 - val_loss: 0.1139 - val_calc_accuracy: 0.8758
Epoch 20/50
 - 10s - loss: 0.1067 - calc_accuracy: 0.8758 - val_loss: 0.0960 - val_calc_accuracy: 0.8933
Epoch 21/50
 - 10s - loss: 0.0995 - calc_accuracy: 0.8903 - val_loss: 0.0996 - val_calc_accuracy: 0.8849
Epoch 22/50
 - 10s - loss: 0.0997 - calc_accuracy: 0.8921 - val_loss: 0.1050 - val_calc_accuracy: 0.8887
Epoch 23/50
 - 10s - loss: 0.0939 - calc_accuracy: 0.8963 - val_loss: 0.0841 - val_calc_accuracy: 0.9108
Epoch 24/50
 - 10s - loss: 0.0882 - calc_accuracy: 0.9094 - val_loss: 0.0895 - val_calc_accuracy: 0.9009
Epoch 25/50
 - 10s - loss: 0.0875 - calc_accuracy: 0.9082 - val_loss: 0.0859 - val_calc_accuracy: 0.9078
Epoch 26/50
 - 10s - loss: 0.0827 - calc_accuracy: 0.9190 - val_loss: 0.0785 - val_calc_accuracy: 0.9192
Epoch 27/50
 - 10s - loss: 0.0820 - calc_accuracy: 0.9164 - val_loss: 0.0833 - val_calc_accuracy: 0.9146
Epoch 28/50
 - 10s - loss: 0.0779 - calc_accuracy: 0.9297 - val_loss: 0.0785 - val_calc_accuracy: 0.9184
Epoch 29/50
 - 10s - loss: 0.0780 - calc_accuracy: 0.9270 - val_loss: 0.0787 - val_calc_accuracy: 0.9177
Epoch 30/50
 - 10s - loss: 0.0737 - calc_accuracy: 0.9313 - val_loss: 0.0805 - val_calc_accuracy: 0.9215
Epoch 31/50
 - 10s - loss: 0.0718 - calc_accuracy: 0.9365 - val_loss: 0.0733 - val_calc_accuracy: 0.9291
Epoch 32/50
 - 10s - loss: 0.0683 - calc_accuracy: 0.9417 - val_loss: 0.0723 - val_calc_accuracy: 0.9276
Epoch 33/50
 - 10s - loss: 0.0667 - calc_accuracy: 0.9429 - val_loss: 0.0695 - val_calc_accuracy: 0.9337
Epoch 34/50
 - 10s - loss: 0.0641 - calc_accuracy: 0.9471 - val_loss: 0.0642 - val_calc_accuracy: 0.9413
Epoch 35/50
 - 10s - loss: 0.0610 - calc_accuracy: 0.9502 - val_loss: 0.0678 - val_calc_accuracy: 0.9337
Epoch 36/50
 - 10s - loss: 0.0602 - calc_accuracy: 0.9488 - val_loss: 0.0692 - val_calc_accuracy: 0.9322
Epoch 37/50
 - 10s - loss: 0.0582 - calc_accuracy: 0.9552 - val_loss: 0.0634 - val_calc_accuracy: 0.9360
Epoch 38/50
 - 10s - loss: 0.0556 - calc_accuracy: 0.9576 - val_loss: 0.0616 - val_calc_accuracy: 0.9444
Epoch 39/50
 - 10s - loss: 0.0541 - calc_accuracy: 0.9584 - val_loss: 0.0590 - val_calc_accuracy: 0.9466
Epoch 40/50
 - 10s - loss: 0.0515 - calc_accuracy: 0.9618 - val_loss: 0.0578 - val_calc_accuracy: 0.9436
Epoch 41/50
 - 10s - loss: 0.0522 - calc_accuracy: 0.9620 - val_loss: 0.0572 - val_calc_accuracy: 0.9459
Epoch 42/50
 - 10s - loss: 0.0482 - calc_accuracy: 0.9705 - val_loss: 0.0569 - val_calc_accuracy: 0.9466
Epoch 43/50
 - 10s - loss: 0.0500 - calc_accuracy: 0.9646 - val_loss: 0.0588 - val_calc_accuracy: 0.9436
Epoch 44/50
 - 10s - loss: 0.0473 - calc_accuracy: 0.9703 - val_loss: 0.0527 - val_calc_accuracy: 0.9512
Epoch 45/50
 - 10s - loss: 0.0448 - calc_accuracy: 0.9727 - val_loss: 0.0517 - val_calc_accuracy: 0.9558
Epoch 46/50
 - 10s - loss: 0.0446 - calc_accuracy: 0.9751 - val_loss: 0.0629 - val_calc_accuracy: 0.9383
Epoch 47/50
 - 10s - loss: 0.0456 - calc_accuracy: 0.9733 - val_loss: 0.0548 - val_calc_accuracy: 0.9558
Epoch 48/50
 - 10s - loss: 0.0428 - calc_accuracy: 0.9773 - val_loss: 0.0512 - val_calc_accuracy: 0.9520
Epoch 49/50
 - 10s - loss: 0.0435 - calc_accuracy: 0.9771 - val_loss: 0.0523 - val_calc_accuracy: 0.9527
Epoch 50/50
 - 10s - loss: 0.0412 - calc_accuracy: 0.9779 - val_loss: 0.0526 - val_calc_accuracy: 0.9527
Test accuracy: 0.9527439024390244
Train on 4976 samples, validate on 1312 samples
Epoch 1/50
 - 34s - loss: 0.2863 - calc_accuracy: 0.5058 - val_loss: 0.4504 - val_calc_accuracy: 0.5000
Epoch 2/50
 - 33s - loss: 0.2589 - calc_accuracy: 0.4980 - val_loss: 0.4493 - val_calc_accuracy: 0.5000
Epoch 3/50
 - 33s - loss: 0.2594 - calc_accuracy: 0.4978 - val_loss: 0.4656 - val_calc_accuracy: 0.5000
Epoch 4/50
 - 33s - loss: 0.2574 - calc_accuracy: 0.5020 - val_loss: 0.4691 - val_calc_accuracy: 0.5000
Epoch 5/50
 - 33s - loss: 0.2569 - calc_accuracy: 0.5076 - val_loss: 0.4724 - val_calc_accuracy: 0.5000
Epoch 6/50
 - 33s - loss: 0.2565 - calc_accuracy: 0.5113 - val_loss: 0.4761 - val_calc_accuracy: 0.5000
Epoch 7/50
 - 33s - loss: 0.2604 - calc_accuracy: 0.4922 - val_loss: 0.4744 - val_calc_accuracy: 0.5000
Epoch 8/50
 - 33s - loss: 0.2563 - calc_accuracy: 0.5068 - val_loss: 0.4718 - val_calc_accuracy: 0.5000
Epoch 9/50
 - 33s - loss: 0.2572 - calc_accuracy: 0.4996 - val_loss: 0.4782 - val_calc_accuracy: 0.5000
Epoch 10/50
 - 33s - loss: 0.2563 - calc_accuracy: 0.5034 - val_loss: 0.4704 - val_calc_accuracy: 0.5000
Epoch 11/50
 - 33s - loss: 0.2557 - calc_accuracy: 0.5038 - val_loss: 0.4753 - val_calc_accuracy: 0.5000
Epoch 12/50
 - 33s - loss: 0.2541 - calc_accuracy: 0.5084 - val_loss: 0.4726 - val_calc_accuracy: 0.5000
Epoch 13/50
 - 33s - loss: 0.2545 - calc_accuracy: 0.5040 - val_loss: 0.4780 - val_calc_accuracy: 0.5000
Epoch 14/50
 - 33s - loss: 0.2557 - calc_accuracy: 0.4928 - val_loss: 0.4729 - val_calc_accuracy: 0.5000
Epoch 15/50
 - 33s - loss: 0.2556 - calc_accuracy: 0.4952 - val_loss: 0.4761 - val_calc_accuracy: 0.5000
Epoch 16/50
 - 33s - loss: 0.2544 - calc_accuracy: 0.5098 - val_loss: 0.4660 - val_calc_accuracy: 0.5000
Epoch 17/50
 - 33s - loss: 0.2555 - calc_accuracy: 0.5000 - val_loss: 0.4773 - val_calc_accuracy: 0.5000
Epoch 18/50
 - 33s - loss: 0.2550 - calc_accuracy: 0.4881 - val_loss: 0.4851 - val_calc_accuracy: 0.5000
Epoch 19/50
 - 33s - loss: 0.2542 - calc_accuracy: 0.5010 - val_loss: 0.4865 - val_calc_accuracy: 0.5000
Epoch 20/50
 - 33s - loss: 0.2534 - calc_accuracy: 0.5052 - val_loss: 0.4842 - val_calc_accuracy: 0.5000
Epoch 21/50
 - 33s - loss: 0.2550 - calc_accuracy: 0.4940 - val_loss: 0.4781 - val_calc_accuracy: 0.5000
Epoch 22/50
 - 33s - loss: 0.2541 - calc_accuracy: 0.5036 - val_loss: 0.4870 - val_calc_accuracy: 0.5000
Epoch 23/50
 - 33s - loss: 0.2541 - calc_accuracy: 0.4972 - val_loss: 0.4692 - val_calc_accuracy: 0.5000
Epoch 24/50
 - 33s - loss: 0.2576 - calc_accuracy: 0.5018 - val_loss: 0.4813 - val_calc_accuracy: 0.5000
Epoch 25/50
 - 33s - loss: 0.2542 - calc_accuracy: 0.4994 - val_loss: 0.4733 - val_calc_accuracy: 0.5000
Epoch 26/50
 - 33s - loss: 0.2539 - calc_accuracy: 0.5012 - val_loss: 0.4793 - val_calc_accuracy: 0.5000
Epoch 27/50
 - 33s - loss: 0.2527 - calc_accuracy: 0.5090 - val_loss: 0.4860 - val_calc_accuracy: 0.5000
Epoch 28/50
 - 33s - loss: 0.2531 - calc_accuracy: 0.5131 - val_loss: 0.4499 - val_calc_accuracy: 0.5000
Epoch 29/50
 - 33s - loss: 0.2531 - calc_accuracy: 0.5117 - val_loss: 0.4812 - val_calc_accuracy: 0.5000
Epoch 30/50
 - 33s - loss: 0.2547 - calc_accuracy: 0.4920 - val_loss: 0.4849 - val_calc_accuracy: 0.5000
Epoch 31/50
 - 33s - loss: 0.2541 - calc_accuracy: 0.4986 - val_loss: 0.4804 - val_calc_accuracy: 0.5000
Epoch 32/50
 - 33s - loss: 0.2539 - calc_accuracy: 0.4942 - val_loss: 0.4844 - val_calc_accuracy: 0.5000
Epoch 33/50
 - 33s - loss: 0.2533 - calc_accuracy: 0.5113 - val_loss: 0.4785 - val_calc_accuracy: 0.5000
Epoch 34/50
 - 33s - loss: 0.2549 - calc_accuracy: 0.5054 - val_loss: 0.4760 - val_calc_accuracy: 0.5000
Epoch 35/50
 - 33s - loss: 0.2545 - calc_accuracy: 0.4988 - val_loss: 0.4883 - val_calc_accuracy: 0.5000
Epoch 36/50
 - 33s - loss: 0.2539 - calc_accuracy: 0.5016 - val_loss: 0.4867 - val_calc_accuracy: 0.5000
Epoch 37/50
 - 33s - loss: 0.2532 - calc_accuracy: 0.5042 - val_loss: 0.4696 - val_calc_accuracy: 0.5000
Epoch 38/50
 - 33s - loss: 0.2538 - calc_accuracy: 0.5054 - val_loss: 0.4745 - val_calc_accuracy: 0.5000
Epoch 39/50
 - 33s - loss: 0.2545 - calc_accuracy: 0.4994 - val_loss: 0.4808 - val_calc_accuracy: 0.5000
Epoch 40/50
 - 33s - loss: 0.2557 - calc_accuracy: 0.4936 - val_loss: 0.4823 - val_calc_accuracy: 0.5000
Epoch 41/50
 - 33s - loss: 0.2542 - calc_accuracy: 0.4974 - val_loss: 0.4894 - val_calc_accuracy: 0.5000
Epoch 42/50
 - 33s - loss: 0.2536 - calc_accuracy: 0.4920 - val_loss: 0.4809 - val_calc_accuracy: 0.5000
Epoch 43/50
 - 33s - loss: 0.2531 - calc_accuracy: 0.5094 - val_loss: 0.4764 - val_calc_accuracy: 0.5000
Epoch 44/50
 - 33s - loss: 0.2528 - calc_accuracy: 0.5177 - val_loss: 0.4767 - val_calc_accuracy: 0.5000
Epoch 45/50
 - 33s - loss: 0.2539 - calc_accuracy: 0.5042 - val_loss: 0.4859 - val_calc_accuracy: 0.5000
Epoch 46/50
 - 33s - loss: 0.2532 - calc_accuracy: 0.4934 - val_loss: 0.4856 - val_calc_accuracy: 0.5000
Epoch 47/50
 - 33s - loss: 0.2551 - calc_accuracy: 0.4922 - val_loss: 0.4915 - val_calc_accuracy: 0.5000
Epoch 48/50
 - 33s - loss: 0.2543 - calc_accuracy: 0.4879 - val_loss: 0.4745 - val_calc_accuracy: 0.5000
Epoch 49/50
 - 33s - loss: 0.2538 - calc_accuracy: 0.5024 - val_loss: 0.4923 - val_calc_accuracy: 0.5000
Epoch 50/50
 - 33s - loss: 0.2533 - calc_accuracy: 0.4992 - val_loss: 0.4782 - val_calc_accuracy: 0.5000
Test accuracy: 0.5
Train on 4976 samples, validate on 1312 samples
Epoch 1/50
 - 34s - loss: 0.2690 - calc_accuracy: 0.5018 - val_loss: 0.4571 - val_calc_accuracy: 0.5000
Epoch 2/50
 - 33s - loss: 0.2555 - calc_accuracy: 0.5187 - val_loss: 0.4575 - val_calc_accuracy: 0.5000
Epoch 3/50
 - 33s - loss: 0.2605 - calc_accuracy: 0.5092 - val_loss: 0.4442 - val_calc_accuracy: 0.5000
Epoch 4/50
 - 33s - loss: 0.2553 - calc_accuracy: 0.5177 - val_loss: 0.4207 - val_calc_accuracy: 0.5000
Epoch 5/50
 - 33s - loss: 0.2522 - calc_accuracy: 0.5372 - val_loss: 0.3327 - val_calc_accuracy: 0.5008
Epoch 6/50
 - 33s - loss: 0.2431 - calc_accuracy: 0.5683 - val_loss: 0.4159 - val_calc_accuracy: 0.5000
Epoch 7/50
 - 33s - loss: 0.2282 - calc_accuracy: 0.6174 - val_loss: 0.2819 - val_calc_accuracy: 0.5274
Epoch 8/50
 - 33s - loss: 0.2003 - calc_accuracy: 0.6877 - val_loss: 0.1930 - val_calc_accuracy: 0.7005
Epoch 9/50
 - 33s - loss: 0.1936 - calc_accuracy: 0.7114 - val_loss: 0.1917 - val_calc_accuracy: 0.7127
Epoch 10/50
 - 33s - loss: 0.1782 - calc_accuracy: 0.7381 - val_loss: 0.1766 - val_calc_accuracy: 0.7462
Epoch 11/50
 - 33s - loss: 0.1720 - calc_accuracy: 0.7504 - val_loss: 0.1485 - val_calc_accuracy: 0.7950
Epoch 12/50
 - 33s - loss: 0.1598 - calc_accuracy: 0.7753 - val_loss: 0.1458 - val_calc_accuracy: 0.8056
Epoch 13/50
 - 33s - loss: 0.1543 - calc_accuracy: 0.7888 - val_loss: 0.1385 - val_calc_accuracy: 0.8110
Epoch 14/50
 - 33s - loss: 0.1461 - calc_accuracy: 0.8039 - val_loss: 0.1584 - val_calc_accuracy: 0.7668
Epoch 15/50
 - 33s - loss: 0.1401 - calc_accuracy: 0.8181 - val_loss: 0.1240 - val_calc_accuracy: 0.8468
Epoch 16/50
 - 33s - loss: 0.1350 - calc_accuracy: 0.8254 - val_loss: 0.1122 - val_calc_accuracy: 0.8697
Epoch 17/50
 - 33s - loss: 0.1277 - calc_accuracy: 0.8390 - val_loss: 0.1121 - val_calc_accuracy: 0.8704
Epoch 18/50
 - 33s - loss: 0.1228 - calc_accuracy: 0.8487 - val_loss: 0.1048 - val_calc_accuracy: 0.8788
Epoch 19/50
 - 33s - loss: 0.1166 - calc_accuracy: 0.8613 - val_loss: 0.1197 - val_calc_accuracy: 0.8445
Epoch 20/50
 - 33s - loss: 0.1157 - calc_accuracy: 0.8589 - val_loss: 0.0963 - val_calc_accuracy: 0.9002
Epoch 21/50
 - 33s - loss: 0.1116 - calc_accuracy: 0.8686 - val_loss: 0.0970 - val_calc_accuracy: 0.9047
Epoch 22/50
 - 33s - loss: 0.1071 - calc_accuracy: 0.8802 - val_loss: 0.1008 - val_calc_accuracy: 0.8902
Epoch 23/50
 - 33s - loss: 0.1052 - calc_accuracy: 0.8828 - val_loss: 0.0907 - val_calc_accuracy: 0.9024
Epoch 24/50
 - 33s - loss: 0.1033 - calc_accuracy: 0.8871 - val_loss: 0.0985 - val_calc_accuracy: 0.8902
Epoch 25/50
 - 33s - loss: 0.0995 - calc_accuracy: 0.8903 - val_loss: 0.0913 - val_calc_accuracy: 0.9070
Epoch 26/50
 - 33s - loss: 0.0990 - calc_accuracy: 0.8949 - val_loss: 0.0875 - val_calc_accuracy: 0.9093
Epoch 27/50
 - 33s - loss: 0.0945 - calc_accuracy: 0.9025 - val_loss: 0.0900 - val_calc_accuracy: 0.8963
Epoch 28/50
 - 33s - loss: 0.0941 - calc_accuracy: 0.8987 - val_loss: 0.0912 - val_calc_accuracy: 0.9062
Epoch 29/50
 - 33s - loss: 0.0899 - calc_accuracy: 0.9084 - val_loss: 0.0842 - val_calc_accuracy: 0.9177
Epoch 30/50
 - 33s - loss: 0.0905 - calc_accuracy: 0.9104 - val_loss: 0.0872 - val_calc_accuracy: 0.9146
Epoch 31/50
 - 33s - loss: 0.0902 - calc_accuracy: 0.9049 - val_loss: 0.0877 - val_calc_accuracy: 0.9101
Epoch 32/50
 - 33s - loss: 0.0873 - calc_accuracy: 0.9120 - val_loss: 0.0954 - val_calc_accuracy: 0.8986
Epoch 33/50
 - 33s - loss: 0.0860 - calc_accuracy: 0.9130 - val_loss: 0.0832 - val_calc_accuracy: 0.9192
Epoch 34/50
 - 33s - loss: 0.0846 - calc_accuracy: 0.9172 - val_loss: 0.0831 - val_calc_accuracy: 0.9101
Epoch 35/50
 - 33s - loss: 0.0847 - calc_accuracy: 0.9160 - val_loss: 0.0786 - val_calc_accuracy: 0.9177
Epoch 36/50
 - 33s - loss: 0.0826 - calc_accuracy: 0.9198 - val_loss: 0.0800 - val_calc_accuracy: 0.9230
Epoch 37/50
 - 33s - loss: 0.0803 - calc_accuracy: 0.9202 - val_loss: 0.0771 - val_calc_accuracy: 0.9177
Epoch 38/50
 - 33s - loss: 0.0791 - calc_accuracy: 0.9212 - val_loss: 0.0768 - val_calc_accuracy: 0.9200
Epoch 39/50
 - 33s - loss: 0.0795 - calc_accuracy: 0.9248 - val_loss: 0.0772 - val_calc_accuracy: 0.9299
Epoch 40/50
 - 33s - loss: 0.0773 - calc_accuracy: 0.9283 - val_loss: 0.0737 - val_calc_accuracy: 0.9184
Epoch 41/50
 - 33s - loss: 0.0762 - calc_accuracy: 0.9266 - val_loss: 0.0741 - val_calc_accuracy: 0.9329
Epoch 42/50
 - 33s - loss: 0.0763 - calc_accuracy: 0.9262 - val_loss: 0.0738 - val_calc_accuracy: 0.9268
Epoch 43/50
 - 33s - loss: 0.0754 - calc_accuracy: 0.9297 - val_loss: 0.0791 - val_calc_accuracy: 0.9268
Epoch 44/50
 - 33s - loss: 0.0751 - calc_accuracy: 0.9289 - val_loss: 0.0783 - val_calc_accuracy: 0.9162
Epoch 45/50
 - 33s - loss: 0.0725 - calc_accuracy: 0.9309 - val_loss: 0.0743 - val_calc_accuracy: 0.9253
Epoch 46/50
 - 33s - loss: 0.0739 - calc_accuracy: 0.9333 - val_loss: 0.0733 - val_calc_accuracy: 0.9261
Epoch 47/50
 - 33s - loss: 0.0712 - calc_accuracy: 0.9363 - val_loss: 0.0753 - val_calc_accuracy: 0.9245
Epoch 48/50
 - 33s - loss: 0.0726 - calc_accuracy: 0.9307 - val_loss: 0.0705 - val_calc_accuracy: 0.9268
Epoch 49/50
 - 33s - loss: 0.0707 - calc_accuracy: 0.9385 - val_loss: 0.0738 - val_calc_accuracy: 0.9268
Epoch 50/50
 - 33s - loss: 0.0696 - calc_accuracy: 0.9373 - val_loss: 0.0691 - val_calc_accuracy: 0.9329
Test accuracy: 0.9329268292682927
Train on 4976 samples, validate on 1312 samples
Epoch 1/50
 - 12s - loss: 0.2899 - calc_accuracy: 0.5052 - val_loss: 0.3850 - val_calc_accuracy: 0.5000
Epoch 2/50
 - 11s - loss: 0.2532 - calc_accuracy: 0.5171 - val_loss: 0.3605 - val_calc_accuracy: 0.5000
Epoch 3/50
 - 11s - loss: 0.2517 - calc_accuracy: 0.5279 - val_loss: 0.3266 - val_calc_accuracy: 0.5114
Epoch 4/50
 - 11s - loss: 0.2498 - calc_accuracy: 0.5478 - val_loss: 0.2746 - val_calc_accuracy: 0.5488
Epoch 5/50
 - 11s - loss: 0.2421 - calc_accuracy: 0.5926 - val_loss: 0.2604 - val_calc_accuracy: 0.5686
Epoch 6/50
 - 11s - loss: 0.2307 - calc_accuracy: 0.6210 - val_loss: 0.2236 - val_calc_accuracy: 0.6616
Epoch 7/50
 - 11s - loss: 0.2357 - calc_accuracy: 0.6085 - val_loss: 0.2273 - val_calc_accuracy: 0.6341
Epoch 8/50
 - 11s - loss: 0.2147 - calc_accuracy: 0.6551 - val_loss: 0.1924 - val_calc_accuracy: 0.6951
Epoch 9/50
 - 11s - loss: 0.2009 - calc_accuracy: 0.6855 - val_loss: 0.1750 - val_calc_accuracy: 0.7287
Epoch 10/50
 - 11s - loss: 0.1839 - calc_accuracy: 0.7309 - val_loss: 0.1772 - val_calc_accuracy: 0.7370
Epoch 11/50
 - 11s - loss: 0.1687 - calc_accuracy: 0.7532 - val_loss: 0.1472 - val_calc_accuracy: 0.7896
Epoch 12/50
 - 11s - loss: 0.1606 - calc_accuracy: 0.7709 - val_loss: 0.1309 - val_calc_accuracy: 0.8255
Epoch 13/50
 - 11s - loss: 0.1476 - calc_accuracy: 0.7936 - val_loss: 0.1331 - val_calc_accuracy: 0.8247
Epoch 14/50
 - 11s - loss: 0.1391 - calc_accuracy: 0.8061 - val_loss: 0.1236 - val_calc_accuracy: 0.8415
Epoch 15/50
 - 11s - loss: 0.1310 - calc_accuracy: 0.8284 - val_loss: 0.1238 - val_calc_accuracy: 0.8422
Epoch 16/50
 - 11s - loss: 0.1235 - calc_accuracy: 0.8461 - val_loss: 0.1065 - val_calc_accuracy: 0.8666
Epoch 17/50
 - 11s - loss: 0.1171 - calc_accuracy: 0.8483 - val_loss: 0.1028 - val_calc_accuracy: 0.8788
Epoch 18/50
 - 11s - loss: 0.1146 - calc_accuracy: 0.8537 - val_loss: 0.0969 - val_calc_accuracy: 0.8880
Epoch 19/50
 - 11s - loss: 0.1031 - calc_accuracy: 0.8768 - val_loss: 0.0953 - val_calc_accuracy: 0.8994
Epoch 20/50
 - 11s - loss: 0.1015 - calc_accuracy: 0.8794 - val_loss: 0.0948 - val_calc_accuracy: 0.8933
Epoch 21/50
 - 11s - loss: 0.0925 - calc_accuracy: 0.8977 - val_loss: 0.0892 - val_calc_accuracy: 0.9017
Epoch 22/50
 - 11s - loss: 0.0872 - calc_accuracy: 0.9078 - val_loss: 0.0804 - val_calc_accuracy: 0.9154
Epoch 23/50
 - 11s - loss: 0.0833 - calc_accuracy: 0.9128 - val_loss: 0.0818 - val_calc_accuracy: 0.9101
Epoch 24/50
 - 11s - loss: 0.0789 - calc_accuracy: 0.9186 - val_loss: 0.0756 - val_calc_accuracy: 0.9146
Epoch 25/50
 - 11s - loss: 0.0753 - calc_accuracy: 0.9188 - val_loss: 0.0816 - val_calc_accuracy: 0.9207
Epoch 26/50
 - 11s - loss: 0.0750 - calc_accuracy: 0.9246 - val_loss: 0.0737 - val_calc_accuracy: 0.9253
Epoch 27/50
 - 11s - loss: 0.0680 - calc_accuracy: 0.9325 - val_loss: 0.0730 - val_calc_accuracy: 0.9268
Epoch 28/50
 - 11s - loss: 0.0695 - calc_accuracy: 0.9293 - val_loss: 0.0723 - val_calc_accuracy: 0.9123
Epoch 29/50
 - 11s - loss: 0.0656 - calc_accuracy: 0.9375 - val_loss: 0.0659 - val_calc_accuracy: 0.9352
Epoch 30/50
 - 11s - loss: 0.0637 - calc_accuracy: 0.9367 - val_loss: 0.0798 - val_calc_accuracy: 0.9131
Epoch 31/50
 - 11s - loss: 0.0604 - calc_accuracy: 0.9431 - val_loss: 0.0621 - val_calc_accuracy: 0.9413
Epoch 32/50
 - 11s - loss: 0.0585 - calc_accuracy: 0.9463 - val_loss: 0.0633 - val_calc_accuracy: 0.9329
Epoch 33/50
 - 11s - loss: 0.0562 - calc_accuracy: 0.9490 - val_loss: 0.0704 - val_calc_accuracy: 0.9276
Epoch 34/50
 - 11s - loss: 0.0541 - calc_accuracy: 0.9560 - val_loss: 0.0631 - val_calc_accuracy: 0.9451
Epoch 35/50
 - 11s - loss: 0.0530 - calc_accuracy: 0.9526 - val_loss: 0.0633 - val_calc_accuracy: 0.9367
Epoch 36/50
 - 11s - loss: 0.0492 - calc_accuracy: 0.9646 - val_loss: 0.0573 - val_calc_accuracy: 0.9413
Epoch 37/50
 - 11s - loss: 0.0485 - calc_accuracy: 0.9622 - val_loss: 0.0529 - val_calc_accuracy: 0.9527
Epoch 38/50
 - 11s - loss: 0.0498 - calc_accuracy: 0.9620 - val_loss: 0.0495 - val_calc_accuracy: 0.9543
Epoch 39/50
 - 11s - loss: 0.0433 - calc_accuracy: 0.9725 - val_loss: 0.0542 - val_calc_accuracy: 0.9527
Epoch 40/50
 - 11s - loss: 0.0419 - calc_accuracy: 0.9743 - val_loss: 0.0516 - val_calc_accuracy: 0.9451
Epoch 41/50
 - 11s - loss: 0.0434 - calc_accuracy: 0.9735 - val_loss: 0.0490 - val_calc_accuracy: 0.9550
Epoch 42/50
 - 11s - loss: 0.0383 - calc_accuracy: 0.9807 - val_loss: 0.0526 - val_calc_accuracy: 0.9512
Epoch 43/50
 - 11s - loss: 0.0395 - calc_accuracy: 0.9783 - val_loss: 0.0490 - val_calc_accuracy: 0.9604
Epoch 44/50
 - 11s - loss: 0.0350 - calc_accuracy: 0.9849 - val_loss: 0.0452 - val_calc_accuracy: 0.9619
Epoch 45/50
 - 11s - loss: 0.0357 - calc_accuracy: 0.9831 - val_loss: 0.0452 - val_calc_accuracy: 0.9642
Epoch 46/50
 - 11s - loss: 0.0363 - calc_accuracy: 0.9815 - val_loss: 0.0433 - val_calc_accuracy: 0.9642
Epoch 47/50
 - 11s - loss: 0.0328 - calc_accuracy: 0.9877 - val_loss: 0.0419 - val_calc_accuracy: 0.9672
Epoch 48/50
 - 11s - loss: 0.0323 - calc_accuracy: 0.9877 - val_loss: 0.0441 - val_calc_accuracy: 0.9657
Epoch 49/50
 - 11s - loss: 0.0353 - calc_accuracy: 0.9819 - val_loss: 0.0423 - val_calc_accuracy: 0.9680
Epoch 50/50
 - 11s - loss: 0.0300 - calc_accuracy: 0.9912 - val_loss: 0.0406 - val_calc_accuracy: 0.9680
Test accuracy: 0.9679878048780488
{'pool_size_2': 4, 'Conv2D': 16, 'pool_size_3': 8, 'activation_4': 'tanh', 'activation_1': 'tanh', 'activation_3': 'relu', 'pool_size_1': 2, 'activation_2': 'relu', 'Conv2D_1': 32, 'Dense': 32, 'pool_size_5': 7, 'Conv2D_2': 32, 'pool_size': 7, 'Conv2D_3': 64, 'activation': 'relu', 'pool_size_4': 8}
Evalutation of best performing model:
